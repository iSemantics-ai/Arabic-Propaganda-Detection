{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2065b7ef",
   "metadata": {},
   "source": [
    "# Labeling Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3213a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import emoji\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import util\n",
    "\n",
    "from snorkel.preprocess import preprocessor\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8863f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining data paths\n",
    "prop_data_annotated = \"../data/processed/propaganda_annotated.pkl\"\n",
    "gen_data_annotated = \"../data/processed/genuine_annotated.pkl\"\n",
    "wanlp_prop_data_path = \"../data/raw/task1_train.json\"\n",
    "weakly_labeled_data_path = \"../data/processed/train.json\"\n",
    "lfs_analysis_path = \"../data/processed/lfs_analysis.json\"\n",
    "lfs_dev_labels_path = \"../data/processed/lfs_dev_labels.npy\"\n",
    "lfs_train_labels_path = \"../data/processed/lfs_train_labels.npy\"\n",
    "\n",
    "# we need the lf_dev data to report the performance of LFs\n",
    "# and then remove it with the test data from the unlabaled data\n",
    "lf_dev_data_path = \"../data/processed/lf_dev.json\"\n",
    "test_data_path = \"../data/processed/test_data.json\"\n",
    "\n",
    "# defining lexicons paths\n",
    "proppy_lex_paths = \"../data/raw/proppy_lexicons/*.csv\"\n",
    "loaded_lex_path = \"../data/raw/loaded-language-lexicons.csv\"\n",
    "\n",
    "# loading pre-trained encoders\n",
    "fasttext_model_path = \"../models/cc.ar.300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1bca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the needed fields by the working labeling functions\n",
    "# in case of doing the analysis from scratch, comment the variable\n",
    "\n",
    "# fields = [\n",
    "#     \"tweetid\",\n",
    "#     \"user_profile_description\",\n",
    "#     \"tweet_text\",\n",
    "#     \"is_retweet\",\n",
    "#     \"quote_count\",\n",
    "#     \"reply_count\",\n",
    "#     \"like_count\",\n",
    "#     \"retweet_count\",\n",
    "#     \"hashtags\",\n",
    "#     \"urls\",\n",
    "#     \"user_mentions\",\n",
    "#     \"text\",\n",
    "#     \"emojis\",\n",
    "#     \"word_count\",\n",
    "#     \"docs\",\n",
    "#     \"is_irony\",\n",
    "#     \"is_hate\",\n",
    "#     \"xlmroberta_label\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f9ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(prop_data_annotated)  # [fields]\n",
    "df2 = pd.read_pickle(gen_data_annotated)  # [fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5b56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following lines handle date conversion\n",
    "\n",
    "df1[\"account_creation_date\"] = pd.to_datetime(df1.account_creation_date, unit=\"ms\")\n",
    "df2[\"account_creation_date\"] = pd.to_datetime(df2.account_creation_date, unit=\"ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c84b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the propaganda and genuine users data\n",
    "\n",
    "unlabeled_data = pd.concat([df1, df2], ignore_index=True)\n",
    "unlabeled_data = unlabeled_data.sample(frac=1.0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "150d69b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>docs</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>hate</th>\n",
       "      <th>xlmroberta_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>544945186909220864</td>\n",
       "      <td>607579193</td>\n",
       "      <td>Ø­Ù…ÙˆØ¯ Ø§Ù„Ø¯Ø§Ø®Ù„</td>\n",
       "      <td>alntafat</td>\n",
       "      <td>Ø§Ù„Ø±ÙŠØ§Ø¶, Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©</td>\n",
       "      <td>Ù…Ø´ÙŠÙ†Ø§ Ø¹Ù„Ù‰ Ø¯Ø±Ø¨ Ø§Ù„Ù…Ø¹Ø²Ù‡ ÙˆÙ†Ù‡Ø¬ Ø§Ù„Ø¹ÙˆØ¯ ÙˆÙ…Ù† Ù…Ø¯Ø±Ø³Ù‡ Ø´ÙŠØ® ...</td>\n",
       "      <td>61366.0</td>\n",
       "      <td>6869.0</td>\n",
       "      <td>2012-06-13 00:00:00</td>\n",
       "      <td>RT @axxa00: ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ø³ØªØºÙØ±...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9975724816...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99894624...</td>\n",
       "      <td>{'sequence': 'ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117798852772401152.0</td>\n",
       "      <td>2673203522.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>RT @MOISaudiArabia: Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ Ùˆ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© ÙŠØ±Ø¹Ù‰ Ø­Ù...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9980658888...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99932289...</td>\n",
       "      <td>{'sequence': 'Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweetid        userid user_display_name user_screen_name  \\\n",
       "0     544945186909220864     607579193       Ø­Ù…ÙˆØ¯ Ø§Ù„Ø¯Ø§Ø®Ù„         alntafat   \n",
       "1  1117798852772401152.0  2673203522.0              None             None   \n",
       "\n",
       "             user_reported_location  \\\n",
       "0  Ø§Ù„Ø±ÙŠØ§Ø¶, Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©   \n",
       "1                              None   \n",
       "\n",
       "                            user_profile_description  follower_count  \\\n",
       "0  Ù…Ø´ÙŠÙ†Ø§ Ø¹Ù„Ù‰ Ø¯Ø±Ø¨ Ø§Ù„Ù…Ø¹Ø²Ù‡ ÙˆÙ†Ù‡Ø¬ Ø§Ù„Ø¹ÙˆØ¯ ÙˆÙ…Ù† Ù…Ø¯Ø±Ø³Ù‡ Ø´ÙŠØ® ...         61366.0   \n",
       "1                                               None             NaN   \n",
       "\n",
       "   following_count account_creation_date  \\\n",
       "0           6869.0   2012-06-13 00:00:00   \n",
       "1              NaN                   NaT   \n",
       "\n",
       "                                          tweet_text  ...  hashtags  urls  \\\n",
       "0  RT @axxa00: ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ ...  ...         1     0   \n",
       "1  RT @MOISaudiArabia: Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ Ùˆ...  ...         0     1   \n",
       "\n",
       "   user_mentions                                               text  emojis  \\\n",
       "0              1  ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ø³ØªØºÙØ±...       1   \n",
       "1              1  Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© ÙŠØ±Ø¹Ù‰ Ø­Ù...       0   \n",
       "\n",
       "   word_count                                               docs  \\\n",
       "0          15  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1          13  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                             sarcasm  \\\n",
       "0  {'label': 'Non-Sarcasm', 'score': 0.9975724816...   \n",
       "1  {'label': 'Non-Sarcasm', 'score': 0.9980658888...   \n",
       "\n",
       "                                                hate  \\\n",
       "0  {'label': 'not offensive', 'score': 0.99894624...   \n",
       "1  {'label': 'not offensive', 'score': 0.99932289...   \n",
       "\n",
       "                                    xlmroberta_label  \n",
       "0  {'sequence': 'ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„...  \n",
       "1  {'sequence': 'Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„...  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d7564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196611 entries, 0 to 196610\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   tweetid                   196609 non-null  object \n",
      " 1   userid                    196610 non-null  object \n",
      " 2   user_display_name         187650 non-null  object \n",
      " 3   user_screen_name          187650 non-null  object \n",
      " 4   user_reported_location    146204 non-null  object \n",
      " 5   user_profile_description  183083 non-null  object \n",
      " 6   follower_count            187650 non-null  float64\n",
      " 7   following_count           187650 non-null  float64\n",
      " 8   account_creation_date     187650 non-null  object \n",
      " 9   tweet_text                196611 non-null  object \n",
      " 10  is_retweet                196611 non-null  bool   \n",
      " 11  quote_count               196606 non-null  float64\n",
      " 12  reply_count               196607 non-null  float64\n",
      " 13  like_count                196607 non-null  object \n",
      " 14  retweet_count             196607 non-null  float64\n",
      " 15  hashtags                  196611 non-null  int64  \n",
      " 16  urls                      196611 non-null  int64  \n",
      " 17  user_mentions             196611 non-null  int64  \n",
      " 18  text                      196611 non-null  object \n",
      " 19  emojis                    196611 non-null  int64  \n",
      " 20  word_count                196611 non-null  int64  \n",
      " 21  docs                      196611 non-null  object \n",
      " 22  sarcasm                   196611 non-null  object \n",
      " 23  hate                      196611 non-null  object \n",
      " 24  xlmroberta_label          196611 non-null  object \n",
      "dtypes: bool(1), float64(5), int64(5), object(14)\n",
      "memory usage: 36.2+ MB\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dbd4c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>text</th>\n",
       "      <th>tech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>924924839902793728</td>\n",
       "      <td>RT @Amal_onzi: ğŸ•ŠğŸ’•Ù‡ÙÙˆ Ø¬Ù†Ù’Ø©Ø¨Ø¹ÙÙŠÙ†ÙŠ.</td>\n",
       "      <td>RT : Ù‡Ùˆ Ø¬Ù†Ø©Ø¨Ø¹ÙŠÙ†ÙŠ.</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1074734231887187970</td>\n",
       "      <td>Ø±Ù£ #ØªØ±ÙƒÙŠØ§_ØªØ¬Ø§Ù‡Ø±_Ø¨Ø§Ù„Ù…Ø¹Ø§ØµÙŠ</td>\n",
       "      <td>Ø±Ù£ ØªØ±ÙƒÙŠØ§ ØªØ¬Ø§Ù‡Ø± Ø¨Ø§Ù„Ù…Ø¹Ø§ØµÙŠ</td>\n",
       "      <td>smears - name-calling - loaded language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                        tweet_text  \\\n",
       "0   924924839902793728  RT @Amal_onzi: ğŸ•ŠğŸ’•Ù‡ÙÙˆ Ø¬Ù†Ù’Ø©Ø¨Ø¹ÙÙŠÙ†ÙŠ.   \n",
       "1  1074734231887187970          Ø±Ù£ #ØªØ±ÙƒÙŠØ§_ØªØ¬Ø§Ù‡Ø±_Ø¨Ø§Ù„Ù…Ø¹Ø§ØµÙŠ   \n",
       "\n",
       "                      text                                     tech  label  \n",
       "0        RT : Ù‡Ùˆ Ø¬Ù†Ø©Ø¨Ø¹ÙŠÙ†ÙŠ.                                     None      0  \n",
       "1  Ø±Ù£ ØªØ±ÙƒÙŠØ§ ØªØ¬Ø§Ù‡Ø± Ø¨Ø§Ù„Ù…Ø¹Ø§ØµÙŠ  smears - name-calling - loaded language      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = pd.read_json(lf_dev_data_path)\n",
    "labeled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc6ee7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweetid     500 non-null    int64 \n",
      " 1   tweet_text  500 non-null    object\n",
      " 2   text        500 non-null    object\n",
      " 3   tech        48 non-null     object\n",
      " 4   label       500 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c77e03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>text</th>\n",
       "      <th>tech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>977553193814122498</td>\n",
       "      <td>Ø´Ø§Ø±ÙƒÙˆØ§ Ù…Ø¹Ù†Ø§ .. ÙÙŠ #Ø³Ø§Ø¹Ø©_Ø§Ù„Ø£Ø±Ø¶ Ø§Ù„Ù„ÙŠÙ„Ø© \\nØ³Ø§Ø¹Ø© ÙˆØ§...</td>\n",
       "      <td>Ø´Ø§Ø±ÙƒÙˆØ§ Ù…Ø¹Ù†Ø§ .. ÙÙŠ Ø³Ø§Ø¹Ø© Ø§Ù„Ø£Ø±Ø¶ Ø§Ù„Ù„ÙŠÙ„Ø© Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1005856990436970497</td>\n",
       "      <td>RT @qtfcjohz: ÙØ§Ù„Ù„Ù‡Ù… Ø·Ù‡Ø± Ù‚Ù„ÙˆØ¨Ù†Ø§ Ù…Ù† ÙƒÙ„ Ø¶ÙŠÙ‚ \\nÙˆÙŠ...</td>\n",
       "      <td>RT : Ø§Ù„Ù„Ù‡Ù… Ø·Ù‡Ø± Ù‚Ù„ÙˆØ¨Ù†Ø§ Ù…Ù† ÙƒÙ„ Ø¶ÙŠÙ‚ ÙˆÙŠØ³Ø± Ø£Ù…ÙˆØ±Ù†Ø§ ÙÙŠ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                         tweet_text  \\\n",
       "0   977553193814122498  Ø´Ø§Ø±ÙƒÙˆØ§ Ù…Ø¹Ù†Ø§ .. ÙÙŠ #Ø³Ø§Ø¹Ø©_Ø§Ù„Ø£Ø±Ø¶ Ø§Ù„Ù„ÙŠÙ„Ø© \\nØ³Ø§Ø¹Ø© ÙˆØ§...   \n",
       "1  1005856990436970497  RT @qtfcjohz: ÙØ§Ù„Ù„Ù‡Ù… Ø·Ù‡Ø± Ù‚Ù„ÙˆØ¨Ù†Ø§ Ù…Ù† ÙƒÙ„ Ø¶ÙŠÙ‚ \\nÙˆÙŠ...   \n",
       "\n",
       "                                                text  tech  label  \n",
       "0  Ø´Ø§Ø±ÙƒÙˆØ§ Ù…Ø¹Ù†Ø§ .. ÙÙŠ Ø³Ø§Ø¹Ø© Ø§Ù„Ø£Ø±Ø¶ Ø§Ù„Ù„ÙŠÙ„Ø© Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯ ...  None      0  \n",
       "1  RT : Ø§Ù„Ù„Ù‡Ù… Ø·Ù‡Ø± Ù‚Ù„ÙˆØ¨Ù†Ø§ Ù…Ù† ÙƒÙ„ Ø¶ÙŠÙ‚ ÙˆÙŠØ³Ø± Ø£Ù…ÙˆØ±Ù†Ø§ ÙÙŠ...  None      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_json(test_data_path)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ec62c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 420 entries, 0 to 419\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweetid     420 non-null    int64 \n",
      " 1   tweet_text  420 non-null    object\n",
      " 2   text        420 non-null    object\n",
      " 3   tech        40 non-null     object\n",
      " 4   label       420 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 19.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3beb4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>docs</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>hate</th>\n",
       "      <th>xlmroberta_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>326832860319326208</td>\n",
       "      <td>291216268</td>\n",
       "      <td>Booooooo</td>\n",
       "      <td>_Keano16</td>\n",
       "      <td>None</td>\n",
       "      <td>Ù…Ø§Ù†Ø´Ø³ØªØ± Ù‚ØµØ© Ø­Ø¨ ÙƒÙ„Ù…Ø§ Ø­Ø§ÙˆÙ„Øª Ø§Ù„Ø¥Ø¨ØªØ¹Ø§Ø¯ Ø¹Ù†Ù‡Ø§ Ø§Ù‚ØªØ±Ø¨Øª...</td>\n",
       "      <td>92553.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>2011-05-01 00:00:00</td>\n",
       "      <td>Ø§Ù„ÙŠÙˆÙ… Ù‚Ø§Ø¨Ù„Øª Ù‡Ø§Ù„Ù…Ù„ÙŠØ­ @SirM7md ÙˆØ¬Ù„Ø³Øª Ù…Ø¹Ù‡ ÙˆØªÙ…Ù†ÙŠØª ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„ÙŠÙˆÙ… Ù‚Ø§Ø¨Ù„Øª Ù‡Ø§Ù„Ù…Ù„ÙŠØ­ ÙˆØ¬Ù„Ø³Øª Ù…Ø¹Ù‡ ÙˆØªÙ…Ù†ÙŠØª Ø§Ù†Ù‡Ø§ Ø¨ÙˆÙ‚Øª...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9976009726...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99777406...</td>\n",
       "      <td>{'sequence': 'Ø§Ù„ÙŠÙˆÙ… Ù‚Ø§Ø¨Ù„Øª Ù‡Ø§Ù„Ù…Ù„ÙŠØ­ ÙˆØ¬Ù„Ø³Øª Ù…Ø¹Ù‡ ÙˆØª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1090627394254356480</td>\n",
       "      <td>444707291</td>\n",
       "      <td>Ù‡ÙØ¯Ø¤ Ø¹ÙØ¢Ø´ÙÙ‚Ù’</td>\n",
       "      <td>M6l8l</td>\n",
       "      <td>None</td>\n",
       "      <td>Ø£Ú¯ØªØ¨ Ù„Ø£Ø¹ÙŠØ´ ÙˆØ£Ø¹ÙŠØ´ Ù„Ù€Ù Ø£Ù‚Ø±Ø£ Ø£ÙƒØªÙØ¨ Ø­ØªÙ‘Ù‰ Ù„Ø¢ ØªØ®Ù†Ù‚Ù†ÙŠ...</td>\n",
       "      <td>5481.0</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>2011-12-23 00:00:00</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø«Ø¨Øª Ù‚Ù„ÙˆØ¨Ù†Ø§ Ø¹Ù„Ù‰ Ø¯ÙŠÙ†Ùƒ\\n#Ø§ÙƒØ´ØªØªØª_Ù…Ø¹Ù†Ø§Ù£</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡Ù… Ø«Ø¨Øª Ù‚Ù„ÙˆØ¨Ù†Ø§ Ø¹Ù„Ù‰ Ø¯ÙŠÙ†Ùƒ Ø§ÙƒØ´ØªØªØª Ù…Ø¹Ù†Ø§Ù£</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9975403547...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99853730...</td>\n",
       "      <td>{'sequence': 'Ø§Ù„Ù„Ù‡Ù… Ø«Ø¨Øª Ù‚Ù„ÙˆØ¨Ù†Ø§ Ø¹Ù„Ù‰ Ø¯ÙŠÙ†Ùƒ Ø§ÙƒØ´ØªØªØª...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweetid     userid user_display_name user_screen_name  \\\n",
       "105   326832860319326208  291216268          Booooooo         _Keano16   \n",
       "143  1090627394254356480  444707291      Ù‡ÙØ¯Ø¤ Ø¹ÙØ¢Ø´ÙÙ‚Ù’            M6l8l   \n",
       "\n",
       "    user_reported_location                           user_profile_description  \\\n",
       "105                   None  Ù…Ø§Ù†Ø´Ø³ØªØ± Ù‚ØµØ© Ø­Ø¨ ÙƒÙ„Ù…Ø§ Ø­Ø§ÙˆÙ„Øª Ø§Ù„Ø¥Ø¨ØªØ¹Ø§Ø¯ Ø¹Ù†Ù‡Ø§ Ø§Ù‚ØªØ±Ø¨Øª...   \n",
       "143                   None  Ø£Ú¯ØªØ¨ Ù„Ø£Ø¹ÙŠØ´ ÙˆØ£Ø¹ÙŠØ´ Ù„Ù€Ù Ø£Ù‚Ø±Ø£ Ø£ÙƒØªÙØ¨ Ø­ØªÙ‘Ù‰ Ù„Ø¢ ØªØ®Ù†Ù‚Ù†ÙŠ...   \n",
       "\n",
       "     follower_count  following_count account_creation_date  \\\n",
       "105         92553.0            292.0   2011-05-01 00:00:00   \n",
       "143          5481.0           3740.0   2011-12-23 00:00:00   \n",
       "\n",
       "                                            tweet_text  ...  hashtags  urls  \\\n",
       "105  Ø§Ù„ÙŠÙˆÙ… Ù‚Ø§Ø¨Ù„Øª Ù‡Ø§Ù„Ù…Ù„ÙŠØ­ @SirM7md ÙˆØ¬Ù„Ø³Øª Ù…Ø¹Ù‡ ÙˆØªÙ…Ù†ÙŠØª ...  ...         0     0   \n",
       "143           Ø§Ù„Ù„Ù‡Ù… Ø«Ø¨Øª Ù‚Ù„ÙˆØ¨Ù†Ø§ Ø¹Ù„Ù‰ Ø¯ÙŠÙ†Ùƒ\\n#Ø§ÙƒØ´ØªØªØª_Ù…Ø¹Ù†Ø§Ù£  ...         1     0   \n",
       "\n",
       "     user_mentions                                               text  emojis  \\\n",
       "105              1  Ø§Ù„ÙŠÙˆÙ… Ù‚Ø§Ø¨Ù„Øª Ù‡Ø§Ù„Ù…Ù„ÙŠØ­ ÙˆØ¬Ù„Ø³Øª Ù…Ø¹Ù‡ ÙˆØªÙ…Ù†ÙŠØª Ø§Ù†Ù‡Ø§ Ø¨ÙˆÙ‚Øª...       0   \n",
       "143              0             Ø§Ù„Ù„Ù‡Ù… Ø«Ø¨Øª Ù‚Ù„ÙˆØ¨Ù†Ø§ Ø¹Ù„Ù‰ Ø¯ÙŠÙ†Ùƒ Ø§ÙƒØ´ØªØªØª Ù…Ø¹Ù†Ø§Ù£       0   \n",
       "\n",
       "     word_count                                               docs  \\\n",
       "105          14  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "143           7  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                               sarcasm  \\\n",
       "105  {'label': 'Non-Sarcasm', 'score': 0.9976009726...   \n",
       "143  {'label': 'Non-Sarcasm', 'score': 0.9975403547...   \n",
       "\n",
       "                                                  hate  \\\n",
       "105  {'label': 'not offensive', 'score': 0.99777406...   \n",
       "143  {'label': 'not offensive', 'score': 0.99853730...   \n",
       "\n",
       "                                      xlmroberta_label  \n",
       "105  {'sequence': 'Ø§Ù„ÙŠÙˆÙ… Ù‚Ø§Ø¨Ù„Øª Ù‡Ø§Ù„Ù…Ù„ÙŠØ­ ÙˆØ¬Ù„Ø³Øª Ù…Ø¹Ù‡ ÙˆØª...  \n",
       "143  {'sequence': 'Ø§Ù„Ù„Ù‡Ù… Ø«Ø¨Øª Ù‚Ù„ÙˆØ¨Ù†Ø§ Ø¹Ù„Ù‰ Ø¯ÙŠÙ†Ùƒ Ø§ÙƒØ´ØªØªØª...  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = unlabeled_data[unlabeled_data.tweetid.isin(labeled.tweetid)]\n",
    "labeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f6f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 105 to 195989\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   tweetid                   500 non-null    object \n",
      " 1   userid                    500 non-null    object \n",
      " 2   user_display_name         500 non-null    object \n",
      " 3   user_screen_name          500 non-null    object \n",
      " 4   user_reported_location    295 non-null    object \n",
      " 5   user_profile_description  462 non-null    object \n",
      " 6   follower_count            500 non-null    float64\n",
      " 7   following_count           500 non-null    float64\n",
      " 8   account_creation_date     500 non-null    object \n",
      " 9   tweet_text                500 non-null    object \n",
      " 10  is_retweet                500 non-null    bool   \n",
      " 11  quote_count               500 non-null    float64\n",
      " 12  reply_count               500 non-null    float64\n",
      " 13  like_count                500 non-null    object \n",
      " 14  retweet_count             500 non-null    float64\n",
      " 15  hashtags                  500 non-null    int64  \n",
      " 16  urls                      500 non-null    int64  \n",
      " 17  user_mentions             500 non-null    int64  \n",
      " 18  text                      500 non-null    object \n",
      " 19  emojis                    500 non-null    int64  \n",
      " 20  word_count                500 non-null    int64  \n",
      " 21  docs                      500 non-null    object \n",
      " 22  sarcasm                   500 non-null    object \n",
      " 23  hate                      500 non-null    object \n",
      " 24  xlmroberta_label          500 non-null    object \n",
      "dtypes: bool(1), float64(5), int64(5), object(14)\n",
      "memory usage: 98.1+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d90e2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the labeled tweets from the unlabeled data\n",
    "\n",
    "unlabeled_data = unlabeled_data[~unlabeled_data.tweetid.isin(labeled_data.tweetid)]\n",
    "unlabeled_data = unlabeled_data[~unlabeled_data.tweetid.isin(test.tweetid)]\n",
    "unlabeled_data = unlabeled_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6bc4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data[\"text\"] = labeled_data.text.apply(lambda x: x.replace(\"RT :\", \"\").strip())\n",
    "labeled_data = labeled_data.reset_index(drop=True)\n",
    "labels = [labeled[labeled.tweetid == i].label.values[0] for i in labeled_data.tweetid]\n",
    "labeled_data[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "962055c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure the dataset doesn't contain any null values\n",
    "\n",
    "subset = [\"tweetid\", \"text\", \"quote_count\", \"xlmroberta_label\"]\n",
    "unlabeled_data = unlabeled_data.dropna(subset=subset)\n",
    "unlabeled_data = unlabeled_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d45b9a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195686 entries, 0 to 195685\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   tweetid                   195686 non-null  object \n",
      " 1   userid                    195686 non-null  object \n",
      " 2   user_display_name         186730 non-null  object \n",
      " 3   user_screen_name          186730 non-null  object \n",
      " 4   user_reported_location    145640 non-null  object \n",
      " 5   user_profile_description  182231 non-null  object \n",
      " 6   follower_count            186730 non-null  float64\n",
      " 7   following_count           186730 non-null  float64\n",
      " 8   account_creation_date     186730 non-null  object \n",
      " 9   tweet_text                195686 non-null  object \n",
      " 10  is_retweet                195686 non-null  bool   \n",
      " 11  quote_count               195686 non-null  float64\n",
      " 12  reply_count               195686 non-null  float64\n",
      " 13  like_count                195686 non-null  object \n",
      " 14  retweet_count             195686 non-null  float64\n",
      " 15  hashtags                  195686 non-null  int64  \n",
      " 16  urls                      195686 non-null  int64  \n",
      " 17  user_mentions             195686 non-null  int64  \n",
      " 18  text                      195686 non-null  object \n",
      " 19  emojis                    195686 non-null  int64  \n",
      " 20  word_count                195686 non-null  int64  \n",
      " 21  docs                      195686 non-null  object \n",
      " 22  sarcasm                   195686 non-null  object \n",
      " 23  hate                      195686 non-null  object \n",
      " 24  xlmroberta_label          195686 non-null  object \n",
      "dtypes: bool(1), float64(5), int64(5), object(14)\n",
      "memory usage: 36.0+ MB\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f118b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 26 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   tweetid                   500 non-null    object \n",
      " 1   userid                    500 non-null    object \n",
      " 2   user_display_name         500 non-null    object \n",
      " 3   user_screen_name          500 non-null    object \n",
      " 4   user_reported_location    295 non-null    object \n",
      " 5   user_profile_description  462 non-null    object \n",
      " 6   follower_count            500 non-null    float64\n",
      " 7   following_count           500 non-null    float64\n",
      " 8   account_creation_date     500 non-null    object \n",
      " 9   tweet_text                500 non-null    object \n",
      " 10  is_retweet                500 non-null    bool   \n",
      " 11  quote_count               500 non-null    float64\n",
      " 12  reply_count               500 non-null    float64\n",
      " 13  like_count                500 non-null    object \n",
      " 14  retweet_count             500 non-null    float64\n",
      " 15  hashtags                  500 non-null    int64  \n",
      " 16  urls                      500 non-null    int64  \n",
      " 17  user_mentions             500 non-null    int64  \n",
      " 18  text                      500 non-null    object \n",
      " 19  emojis                    500 non-null    int64  \n",
      " 20  word_count                500 non-null    int64  \n",
      " 21  docs                      500 non-null    object \n",
      " 22  sarcasm                   500 non-null    object \n",
      " 23  hate                      500 non-null    object \n",
      " 24  xlmroberta_label          500 non-null    object \n",
      " 25  label                     500 non-null    int64  \n",
      "dtypes: bool(1), float64(5), int64(6), object(14)\n",
      "memory usage: 98.3+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3182d",
   "metadata": {},
   "source": [
    "### User LFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a17d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = 1\n",
    "gen = 0\n",
    "ab = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9451286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def missing_bio(example):\n",
    "    \"\"\"Label all tweets of a user as propaganda if they don't have a bio.\"\"\"\n",
    "    if pd.isna(example.user_profile_description):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b9b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def missing_loc(example):\n",
    "    \"\"\"Label all tweets of a user as propaganda if they don't have a location.\"\"\"\n",
    "    if pd.isna(example.user_reported_location):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b852b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def created_2018_2019(example):\n",
    "    \"\"\"Label all tweets of a user as propaganda if account is created 2018 or 2019.\"\"\"\n",
    "    if example.account_creation_date.year in [2018, 2019]:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8077985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def created_2011_2012(example):\n",
    "    \"\"\"Label all tweets of a user as transparent if account is created 2011 or 2012.\"\"\"\n",
    "    if example.account_creation_date.year in [2011, 2012]:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "112fc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor(memoize=False)\n",
    "def tokenize_bio(example):\n",
    "    \"\"\"Tokenize text in the bio.\"\"\"\n",
    "    if not pd.isna(example.user_profile_description):\n",
    "        example.bio_tokens = word_tokenize(example.user_profile_description)\n",
    "    else:\n",
    "        example.bio_tokens = None\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "655f9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[tokenize_bio])\n",
    "def bio_keywords(example):\n",
    "    \"\"\"Label all tweets of a user as transparent if bio contains certain lexicons.\"\"\"\n",
    "    keys = [\"Ø§Ù„Ø­Ø³Ø§Ø¨\", \"Ø§Ù„Ø±Ø³Ù…ÙŠ\", \"Ø¹Ø¶Ùˆ\", \"Ø±Ø¦ÙŠØ³\", \"ÙƒØ§ØªØ¨\", \"Ø¥Ø¯Ø§Ø±Ø©\"]\n",
    "    if example.bio_tokens is not None:\n",
    "        if any(np.in1d(keys, example.bio_tokens)):\n",
    "            return gen\n",
    "        else:\n",
    "            return ab\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ed5cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def follow_ratio_prop(example):\n",
    "    \"\"\"Label all tweets of a user as transparent if 0.8 <= follow ratio <= 1.2\"\"\"\n",
    "    num_followers = example.follower_count\n",
    "    num_following = example.following_count\n",
    "    ratio = num_followers / num_following if num_following != 0 else 0\n",
    "    if 0.8 <= ratio <= 1.2:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55f3275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def follow_ratio_gen(example):\n",
    "    \"\"\"Label all tweets of a user as transparent if follow ratio <= 0.2\"\"\"\n",
    "    num_followers = example.follower_count\n",
    "    num_following = example.following_count\n",
    "    ratio = num_followers / num_following if num_following != 0 else 0\n",
    "    if 0.0 <= ratio <= 0.2:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e8431",
   "metadata": {},
   "source": [
    "### Tweet LFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba3b58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_url(example):\n",
    "    \"\"\"Label tweet as transparent if it contains a URL.\"\"\"\n",
    "    if example.urls > 0:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dd1562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_mention(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains a mention.\"\"\"\n",
    "    if example.user_mentions > 0:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ae1e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def labeling_sarcasm(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains the name calling tech (sarcasm).\"\"\"\n",
    "    if len(example.docs.entities) and example.sarcasm[\"label\"] == \"Sarcasm\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "066eae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def labeling_hate(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains the name calling tech (hate).\"\"\"\n",
    "    if len(example.docs.entities) and example.hate[\"label\"] == \"offensive\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a797ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_ent(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains an entity.\"\"\"\n",
    "    if len(example.docs.entities):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daff9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def ent_free(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain any entities.\"\"\"\n",
    "    if len(example.docs.entities):\n",
    "        return ab\n",
    "    else:\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df8bbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_question(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains an question.\"\"\"\n",
    "    for w in example.docs.sentences[0].words:\n",
    "        if w.upos == \"AUX\":\n",
    "            return prop\n",
    "    return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91695adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ø¬Ø§Ù‡Ø±', 'Ø¬Ù‡Ø±', 'ØªØ¬Ø§Ù‡Ø± Ø¨Ø§Ù„Ù…Ø¹Ø§ØµÙŠ', 'Ù…Ø¬Ø§Ù‡Ø±Ø© Ø¨Ø§Ù„Ù…Ø¹Ø§ØµÙŠ', 'ØªØ¬Ø§Ù‡Ø± Ø¨Ø§Ù„Ù…Ø¹Ø§ØµÙ‰']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the manually crafted loaded tokens.\n",
    "# extracted only from the 500 tweets used for labeling functions development.\n",
    "\n",
    "loaded_lexicons = pd.read_csv(loaded_lex_path)[\"loaded-language\"].to_list()\n",
    "loaded_lexicons[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44dbade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factives</th>\n",
       "      <th>hedges</th>\n",
       "      <th>implicatives</th>\n",
       "      <th>report_verbs</th>\n",
       "      <th>bias</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_colloquial_words</th>\n",
       "      <th>positive_colloquial_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø¹Ø§Ø±Ù</td>\n",
       "      <td>ÙˆØ§Ø¶Ø­</td>\n",
       "      <td>ÙŠØ¯ÙŠØ±</td>\n",
       "      <td>ÙŠØªÙ‡Ù…</td>\n",
       "      <td>Ø¥Ø³Ù‚Ø§Ø·</td>\n",
       "      <td>Ø£Ø¨Ùˆ ÙˆØ¬Ù‡ÙŠÙ†</td>\n",
       "      <td>ÙØ§Ù„Ø­</td>\n",
       "      <td>Ù…Ø²ÙˆØ±Ù‡</td>\n",
       "      <td>Ù…ØªØ­Ù…Ø³</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ÙŠØ¯Ø±ÙŠ</td>\n",
       "      <td>ÙÙŠÙ…Ø§ ÙŠØ¨Ø¯Ùˆ</td>\n",
       "      <td>ÙŠØªØ°ÙƒØ±</td>\n",
       "      <td>Ø§ØªÙ‡Ù…</td>\n",
       "      <td>Ø¥Ø¬Ù‡Ø§Ø¶</td>\n",
       "      <td>Ø¨ÙˆØ¬Ù‡ÙŠÙ†</td>\n",
       "      <td>Ø´Ø§Ø·Ø±</td>\n",
       "      <td>Ù…ØºØªØ±Ø¨</td>\n",
       "      <td>Ø­Ù…Ø§Ø³</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factives     hedges implicatives report_verbs    bias negative_words  \\\n",
       "0     Ø¹Ø§Ø±Ù       ÙˆØ§Ø¶Ø­         ÙŠØ¯ÙŠØ±         ÙŠØªÙ‡Ù…  Ø¥Ø³Ù‚Ø§Ø·       Ø£Ø¨Ùˆ ÙˆØ¬Ù‡ÙŠÙ†   \n",
       "1     ÙŠØ¯Ø±ÙŠ  ÙÙŠÙ…Ø§ ÙŠØ¨Ø¯Ùˆ        ÙŠØªØ°ÙƒØ±         Ø§ØªÙ‡Ù…   Ø¥Ø¬Ù‡Ø§Ø¶         Ø¨ÙˆØ¬Ù‡ÙŠÙ†   \n",
       "\n",
       "  positive_words negative_colloquial_words positive_colloquial_words  \n",
       "0           ÙØ§Ù„Ø­                     Ù…Ø²ÙˆØ±Ù‡                     Ù…ØªØ­Ù…Ø³  \n",
       "1           Ø´Ø§Ø·Ø±                     Ù…ØºØªØ±Ø¨                      Ø­Ù…Ø§Ø³  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the proppy lexicons introduced in https://arxiv.org/abs/1912.06810\n",
    "\n",
    "# proppy_lexicons = []\n",
    "# for file in glob.glob(proppy_lex_paths):\n",
    "#     with open(file, encoding=\"utf-8\") as f:\n",
    "#         proppy_lexicons.extend(f.readlines())\n",
    "\n",
    "proppy_lexicons = pd.read_csv(glob.glob(proppy_lex_paths)[0])\n",
    "proppy_lexicons.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04d43494",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# removing diacritization from proppy lexicons\n",
    "\n",
    "# pattern = r\"[\\u0617-\\u061A\\u064B-\\u0652]\"\n",
    "# proppy_lexicons = [re.sub(pattern, \"\", term.strip()) for term in proppy_lexicons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44508a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "proppy_lexicons = proppy_lexicons.to_dict(orient=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3f59a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proppy_lexicons = {k: [w for w in v if not pd.isna(w)] for k, v in proppy_lexicons.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23b939c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in each proppy lexicon type ...\n",
      "[42, 109, 43, 212, 578, 4630, 1950, 1468, 914]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in each proppy lexicon type ...\")\n",
    "print([len(v) for v in proppy_lexicons.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7820a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the proppy lexicons\n",
    "\n",
    "proppy = []\n",
    "for plex in proppy_lexicons:\n",
    "    proppy.extend(plex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7fd6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are removing diacritization from stanza lemmas\n",
    "\n",
    "\n",
    "@preprocessor(memoize=False)\n",
    "def tokenize_tweet(example):\n",
    "    \"\"\"Tokenize and lemmatize text in tweets.\"\"\"\n",
    "    if len(example.docs.sentences):\n",
    "        example.tweet_tokens = [w.text for w in example.docs.sentences[0].words]\n",
    "        example.tweet_lemmas = [re.sub(pattern, \"\", w.lemma) for w in example.docs.sentences[0].words]\n",
    "    else:\n",
    "        example.tweet_tokens = []\n",
    "        example.tweet_lemmas = []\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3364bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor(pre=[tokenize_tweet], memoize=False)\n",
    "def bigram_tweet(example):\n",
    "    \"\"\"Create bigrams of tweet text's tokens and lemmas.\"\"\"\n",
    "    example.bigram_tokens = [\n",
    "        \" \".join(gram) for gram in ngrams(example.tweet_tokens, 2) if len(gram)\n",
    "    ]\n",
    "    example.bigram_lemmas = [\n",
    "        \" \".join(gram) for gram in ngrams(example.tweet_lemmas, 2) if len(gram)\n",
    "    ]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c61587df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def loaded_language(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains any of the loaded lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, loaded_lexicons)) >= 1:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f41749df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])  # [bigram_tweet]\n",
    "def genuine_language(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain any of the loaded lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, loaded_lexicons)) == 0:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "141c7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def loaded_proppy(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains any of the proppy lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, proppy)) >= 1:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa443bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def genuine_proppy(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain any of the proppy lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, proppy)) == 0:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda395f",
   "metadata": {},
   "source": [
    "The following commented codes are to split each proppy lexicon type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a1e553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_space = {}\n",
    "proppy_lfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "168a55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in proppy_lexicons.keys():\n",
    "    code = f\"\"\"\n",
    "@labeling_function(pre=[bigram_tweet])\n",
    "def loaded_proppy_{name}(example):\n",
    "    \\\"\"\"Label tweet as propaganda if it contains any of the proppy lexicons.\\\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, proppy_lexicons[\"{name}\"])) >= 1:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab\n",
    "    \"\"\"\n",
    "    code = compile(code, \"<string>\", \"exec\")\n",
    "    exec(code, globals(), name_space)\n",
    "    proppy_lfs.append(name_space[f\"loaded_proppy_{name}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e225091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in proppy_lexicons.keys():\n",
    "    code = f\"\"\"\n",
    "@labeling_function(pre=[bigram_tweet])\n",
    "def genuine_proppy_{name}(example):\n",
    "    \\\"\"\"Label tweet as transparent if it doesn't contain any of the proppy lexicons.\\\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, proppy_lexicons[\"{name}\"])) == 0:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab\n",
    "    \"\"\"\n",
    "    code = compile(code, \"<string>\", \"exec\")\n",
    "    exec(code, globals(), name_space)\n",
    "    proppy_lfs.append(name_space[f\"genuine_proppy_{name}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26dd1fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proppy_lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a064cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def loaded_hate(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains hate speech (loaded language).\"\"\"\n",
    "    if example.hate[\"label\"] == \"offensive\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da906bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def loaded_sarcasm(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains sarcasm (loaded language).\"\"\"\n",
    "    if example.sarcasm[\"label\"] == \"Sarcasm\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47a41f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def gen_hate(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain hate speech (loaded language).\"\"\"\n",
    "    if example.hate[\"label\"] == \"not offensive\":\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "095a3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def gen_sarcasm(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain sarcasm (loaded language).\"\"\"\n",
    "    if example.sarcasm[\"label\"] == \"Non-Sarcasm\":\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c73753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag_waving\n",
    "\n",
    "flag_engine = re.compile(r\"Number=\\w+\")\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def flag_wave(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains plural pronouns (flag-waving).\"\"\"\n",
    "    for w in example.docs.sentences[0].words:\n",
    "        if (\n",
    "            w.upos == \"PRON\"\n",
    "            and flag_engine.findall(w.feats)[0].split(\"=\")[-1] == \"Plur\"\n",
    "        ):\n",
    "            return prop\n",
    "    return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4437bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Arabic NLTK stop words.\n",
    "arabic_stop_words = stopwords.words(\"arabic\")\n",
    "\n",
    "# removing diacritization from stop words\n",
    "pattern = r\"[\\u0617-\\u061A\\u064B-\\u0652]\"\n",
    "arabic_stop_words = [re.sub(pattern, \"\", w) for w in arabic_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "efebd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[tokenize_tweet])\n",
    "def repetition(example):\n",
    "    \"\"\"Label tweet as propaganda if it has at least one repeated token.\"\"\"\n",
    "    tokens = [word for word in example.tweet_tokens if word not in arabic_stop_words]\n",
    "    tokens = pd.Series(tokens)\n",
    "    if tokens.value_counts().max() >= 2:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0306bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1358824915483435008</td>\n",
       "      <td>#Ø¨ÙŠ_Ø¨ÙŠ_Ø³ÙŠ_ØªØ±Ù†Ø¯ÙŠÙ†Øº: Ø§Ù„Ù†Ø³Ø§Ø¡ \"ØªØ«Ø±Ø«Ø± ÙƒØ«ÙŠØ±Ø§\" Ø±Ø¦ÙŠØ³ Ø£...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1389927866356412416</td>\n",
       "      <td>\"Ø¯Ù‡ Ù…Ø´ Ù…Ø¹ØªÙ‚Ù„ Ø¯Ù‡ Ø£Ø­Ø³Ù† Ù…Ù† Ø§Ù„Ù„ÙˆÙƒØ§Ù†Ø¯Ø©\".. Ø¬Ø¯Ù„ ÙˆØ³Ø®Ø±ÙŠ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1358824915483435008  #Ø¨ÙŠ_Ø¨ÙŠ_Ø³ÙŠ_ØªØ±Ù†Ø¯ÙŠÙ†Øº: Ø§Ù„Ù†Ø³Ø§Ø¡ \"ØªØ«Ø±Ø«Ø± ÙƒØ«ÙŠØ±Ø§\" Ø±Ø¦ÙŠØ³ Ø£...   \n",
       "1  1389927866356412416  \"Ø¯Ù‡ Ù…Ø´ Ù…Ø¹ØªÙ‚Ù„ Ø¯Ù‡ Ø£Ø­Ø³Ù† Ù…Ù† Ø§Ù„Ù„ÙˆÙƒØ§Ù†Ø¯Ø©\".. Ø¬Ø¯Ù„ ÙˆØ³Ø®Ø±ÙŠ...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the WANLP propaganda dataset for distant supervision\n",
    "# dataset source: https://gitlab.com/araieval/propaganda-detection\n",
    "\n",
    "\n",
    "wanlp_train = pd.read_json(wanlp_prop_data_path)\n",
    "\n",
    "label_processing = lambda x: 0 if \"no technique\" in x else 1\n",
    "wanlp_train[\"labels\"] = wanlp_train[\"labels\"].apply(label_processing)\n",
    "\n",
    "wanlp_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f74bfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Process text and remove links, symbols, and diacritization.\"\"\"\n",
    "    # links\n",
    "    clean_text = re.sub(r\"http\\S+|t\\.co/\\S+\", \"\", text)\n",
    "    # mentions\n",
    "    clean_text = re.sub(r\"@\\w+\", \"\", clean_text)\n",
    "    # hashtags\n",
    "    clean_text = re.sub(r\"#\", \"\", clean_text)\n",
    "    clean_text = re.sub(r\"_\", \" \", clean_text)\n",
    "    # tashqeel - from @bakriano\n",
    "    clean_text = re.sub(r\"[\\u0617-\\u061A\\u064B-\\u0652]\", \"\", clean_text)\n",
    "    # emojis\n",
    "    clean_text = emoji.replace_emoji(clean_text, replace=\"\")\n",
    "    # remove new lines and normalize white spaces\n",
    "    clean_text = re.sub(r\"\\s+\", \" \", clean_text)\n",
    "    return clean_text.replace(\"RT :\", \"\").strip()\n",
    "\n",
    "\n",
    "wanlp_train[\"text\"] = wanlp_train[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50aac88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f984b62886a4ebc9368a68f8523a860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = fasttext.load_model(fasttext_model_path)\n",
    "\n",
    "wanlp_hidden_states = []\n",
    "for tweet in tqdm(wanlp_train.text.values, total=len(wanlp_train)):\n",
    "    vec = encoder.get_sentence_vector(tweet)\n",
    "    wanlp_hidden_states.append(list(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9217f5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 300)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wanlp_hidden_states = np.array(wanlp_hidden_states)\n",
    "wanlp_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca53181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor()\n",
    "def get_sim_scores(example):\n",
    "    \"\"\"Get similarity score between tweet and WANLP propaganda tweets.\"\"\"\n",
    "    tweet_vec = encoder.get_sentence_vector(example.text)\n",
    "    sim_scores = util.cos_sim(tweet_vec, wanlp_hidden_states)\n",
    "    example.sim_scores = sim_scores\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8106c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function(pre=[get_sim_scores])\n",
    "def distant_supervision_prop(example):\n",
    "    \"\"\"Label tweet as propaganda based on its most similar WANLP example.\"\"\"\n",
    "    sim_scores = example.sim_scores\n",
    "    most_sim = sim_scores.argmax(dim=-1).item()\n",
    "    if (\n",
    "        wanlp_train.labels.values[most_sim] == 1\n",
    "        and sim_scores[-1][most_sim].item() >= 0.75\n",
    "    ):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33b25f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function(pre=[get_sim_scores])\n",
    "def distant_supervision_gen(example):\n",
    "    \"\"\"Label tweet as transparent based on its most similar WANLP example.\"\"\"\n",
    "    sim_scores = example.sim_scores\n",
    "    most_sim = sim_scores.argmax(dim=-1).item()\n",
    "    if (\n",
    "        wanlp_train.labels.values[most_sim] == 0\n",
    "        and sim_scores[-1][most_sim].item() >= 0.65\n",
    "    ):\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0957a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def slogans(example):\n",
    "    \"\"\"Label tweet as propaganda if it has any of the slogans form.\"\"\"\n",
    "    matches = re.findall(r\"Ù„Ø§ Ù„\\w+\", example.text)\n",
    "    matches += re.findall(r\"Ù†Ø¹Ù… Ù„\\w+\", example.text)\n",
    "    matches += re.findall(r\"Ù„Ø§ Ø¨Ø¯ÙŠÙ„\", example.text)\n",
    "    if len(matches):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c42d91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the manually extracted hated organizations and entities.\n",
    "\n",
    "hitlerum = [\n",
    "    \"Ù‡ØªÙ„Ø±\",\n",
    "    \"Ø§Ù„Ø¨ØºØ¯Ø§Ø¯ÙŠ\",\n",
    "    \"Ø§ÙˆØ±Ø¯ÙˆØºØ§Ù†\",\n",
    "    \"Ù‚Ø·Ø±\",\n",
    "    \"Ø¯Ø§Ø¹Ø´\",\n",
    "    \"Ø­ÙˆØ«ÙŠ\",\n",
    "    \"ØªØ±ÙƒÙŠØ§\",\n",
    "    \"Ø§Ù„Ø´ÙŠØ¹Ø©\",\n",
    "    \"Ø¥ÙŠØ±Ø§Ù†\",\n",
    "    \"Ø§ÙŠØ±Ø§Ù†\",\n",
    "    \"Ø§Ø®ÙˆÙ†Ø¬ÙŠ\",\n",
    "    \"Ø§Ø®ÙˆØ§Ù†\",\n",
    "    \"Ø¥Ø®ÙˆØ§Ù†\",\n",
    "    \"Ø¥Ø®ÙˆØ§Ù†Ø¬ÙŠ\",\n",
    "    \"Ø£ÙˆØ±Ø¯ÙˆØºØ§Ù†\",\n",
    "    \"Ø§Ù„Ø­ÙˆØ«ÙŠ\",\n",
    "    \"Ø§Ù„Ø­ÙˆØ«ÙŠÙŠÙ†\",\n",
    "    \"Ø³ØªØ§Ù„ÙŠÙ†\",\n",
    "    \"Ø§Ù„Ø¥Ø®ÙˆØ§Ù†\",\n",
    "    \"Ø§Ù„Ø§Ø®ÙˆØ§Ù†\",\n",
    "    \"Ø¥Ø±Ù‡Ø§Ø¨ÙŠ\",\n",
    "    \"Ø§Ù„Ø¥Ø±Ù‡Ø§Ø¨ÙŠÙŠÙ†\",\n",
    "    \"Ù…ØªØ·Ø±Ù\",\n",
    "    \"Ø§Ù„Ù…ØªØ·Ø±ÙÙŠÙ†\",\n",
    "    \"Ø´ÙŠØ¹ÙŠ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f9c8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def reductio(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains the Reductio Ad Hitlerum tech.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if any(np.in1d(tweet_ngrams, hitlerum)):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3af0650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def exaggeration(example):\n",
    "    \"\"\"Label tweet as propaganda if has the \"Ø£ÙØ¹Ù„\" preference form.\"\"\"\n",
    "    if not len(example.docs.sentences):\n",
    "        return ab\n",
    "    for w in example.docs.sentences[0].words:\n",
    "        if w.lemma.startswith(\"Ø£\") and w.upos == \"ADJ\":\n",
    "            return prop\n",
    "    return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "637e19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def pronouns(example):\n",
    "    \"\"\"Label tweet as propaganda if has at least one pronoun.\"\"\"\n",
    "    pro_nouns = []\n",
    "    for word in example.docs.sentences[0].words:\n",
    "        if word.upos == \"PRON\":\n",
    "            pro_nouns.append(word.text)\n",
    "    if len(pro_nouns) >= 1:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2f69cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transparent', 'propaganda']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the XLM-RoBERTa Zero-Shot model classes\n",
    "candidate_labels = [\"transparent\", \"propaganda\"]\n",
    "candidate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff795097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def xlmroberta_prop(example):\n",
    "    \"\"\"Label tweet as propaganda based on zero-shot model.\"\"\"\n",
    "    if pd.isna(example.xlmroberta_label):\n",
    "        return ab\n",
    "    if example.xlmroberta_label[\"scores\"][0] >= 0.90:\n",
    "        if example.xlmroberta_label[\"labels\"][0] == candidate_labels[-1]:\n",
    "            return prop\n",
    "        else:\n",
    "            return ab\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b32e8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def xlmroberta_gen(example):\n",
    "    \"\"\"Label tweet as transparent based on zero-shot model.\"\"\"\n",
    "    if pd.isna(example.xlmroberta_label):\n",
    "        return ab\n",
    "    if example.xlmroberta_label[\"scores\"][0] >= 0.90:\n",
    "        if example.xlmroberta_label[\"labels\"][0] == candidate_labels[0]:\n",
    "            return gen\n",
    "        else:\n",
    "            return ab\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "798f259b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 48 LFs used.\n"
     ]
    }
   ],
   "source": [
    "lfs = [\n",
    "    missing_bio,\n",
    "    missing_loc,\n",
    "    created_2018_2019,\n",
    "    created_2011_2012,\n",
    "    bio_keywords,\n",
    "    # follow_ratio_prop,\n",
    "    # follow_ratio_gen,\n",
    "    contain_url,\n",
    "    contain_mention,\n",
    "    labeling_sarcasm,\n",
    "    labeling_hate,\n",
    "    contain_ent,\n",
    "    ent_free,\n",
    "    contain_question,\n",
    "    loaded_language,\n",
    "    genuine_language,\n",
    "    loaded_proppy,\n",
    "    genuine_proppy,\n",
    "    loaded_hate,\n",
    "    loaded_sarcasm,\n",
    "    gen_hate,\n",
    "    gen_sarcasm,\n",
    "    flag_wave,\n",
    "    repetition,\n",
    "    distant_supervision_prop,\n",
    "    distant_supervision_gen,\n",
    "    slogans,\n",
    "    reductio,\n",
    "    exaggeration,\n",
    "    pronouns,\n",
    "    xlmroberta_prop,\n",
    "    xlmroberta_gen,\n",
    "]\n",
    "\n",
    "lfs += proppy_lfs # uncomment this line in case of splitted proppy lex\n",
    "\n",
    "print(f\"We have {len(lfs)} LFs used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06873387",
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6373596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:23<00:00, 21.02it/s]\n"
     ]
    }
   ],
   "source": [
    "L_dev = applier.apply(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "764f0732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_bio</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.076</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_loc</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.410</td>\n",
       "      <td>20</td>\n",
       "      <td>185</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_2018_2019</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.084</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_2011_2012</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.288</td>\n",
       "      <td>127</td>\n",
       "      <td>17</td>\n",
       "      <td>0.881944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bio_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.066</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_url</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_mention</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>29</td>\n",
       "      <td>297</td>\n",
       "      <td>0.088957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_sarcasm</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_hate</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_ent</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.396</td>\n",
       "      <td>34</td>\n",
       "      <td>164</td>\n",
       "      <td>0.171717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_free</th>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.602</td>\n",
       "      <td>288</td>\n",
       "      <td>14</td>\n",
       "      <td>0.953642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_question</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_language</th>\n",
       "      <td>12</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.192</td>\n",
       "      <td>34</td>\n",
       "      <td>62</td>\n",
       "      <td>0.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_language</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.806</td>\n",
       "      <td>390</td>\n",
       "      <td>14</td>\n",
       "      <td>0.965347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy</th>\n",
       "      <td>14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy</th>\n",
       "      <td>15</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.964</td>\n",
       "      <td>436</td>\n",
       "      <td>47</td>\n",
       "      <td>0.902692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_hate</th>\n",
       "      <td>16</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_sarcasm</th>\n",
       "      <td>17</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_hate</th>\n",
       "      <td>18</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.964</td>\n",
       "      <td>439</td>\n",
       "      <td>44</td>\n",
       "      <td>0.908903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_sarcasm</th>\n",
       "      <td>19</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.990</td>\n",
       "      <td>451</td>\n",
       "      <td>45</td>\n",
       "      <td>0.909274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag_wave</th>\n",
       "      <td>20</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.150</td>\n",
       "      <td>7</td>\n",
       "      <td>68</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repetition</th>\n",
       "      <td>21</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.512</td>\n",
       "      <td>25</td>\n",
       "      <td>231</td>\n",
       "      <td>0.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_prop</th>\n",
       "      <td>22</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_gen</th>\n",
       "      <td>23</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.126</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slogans</th>\n",
       "      <td>24</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reductio</th>\n",
       "      <td>25</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exaggeration</th>\n",
       "      <td>26</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.130</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronouns</th>\n",
       "      <td>27</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>36</td>\n",
       "      <td>290</td>\n",
       "      <td>0.110429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_prop</th>\n",
       "      <td>28</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_gen</th>\n",
       "      <td>29</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.120</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_factives</th>\n",
       "      <td>30</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_hedges</th>\n",
       "      <td>31</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_implicatives</th>\n",
       "      <td>32</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_report_verbs</th>\n",
       "      <td>33</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_bias</th>\n",
       "      <td>34</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>32</td>\n",
       "      <td>178</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_negative_words</th>\n",
       "      <td>35</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.322</td>\n",
       "      <td>24</td>\n",
       "      <td>137</td>\n",
       "      <td>0.149068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_positive_words</th>\n",
       "      <td>36</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.478</td>\n",
       "      <td>32</td>\n",
       "      <td>207</td>\n",
       "      <td>0.133891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_negative_colloquial_words</th>\n",
       "      <td>37</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.334</td>\n",
       "      <td>17</td>\n",
       "      <td>150</td>\n",
       "      <td>0.101796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_positive_colloquial_words</th>\n",
       "      <td>38</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>0.133005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_factives</th>\n",
       "      <td>39</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.984</td>\n",
       "      <td>447</td>\n",
       "      <td>46</td>\n",
       "      <td>0.906694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_hedges</th>\n",
       "      <td>40</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.964</td>\n",
       "      <td>438</td>\n",
       "      <td>45</td>\n",
       "      <td>0.906832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_implicatives</th>\n",
       "      <td>41</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.990</td>\n",
       "      <td>449</td>\n",
       "      <td>47</td>\n",
       "      <td>0.905242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_report_verbs</th>\n",
       "      <td>42</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.944</td>\n",
       "      <td>428</td>\n",
       "      <td>45</td>\n",
       "      <td>0.904863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_bias</th>\n",
       "      <td>43</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.578</td>\n",
       "      <td>274</td>\n",
       "      <td>16</td>\n",
       "      <td>0.944828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_negative_words</th>\n",
       "      <td>44</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.676</td>\n",
       "      <td>315</td>\n",
       "      <td>24</td>\n",
       "      <td>0.929204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_positive_words</th>\n",
       "      <td>45</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.520</td>\n",
       "      <td>245</td>\n",
       "      <td>16</td>\n",
       "      <td>0.938697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_negative_colloquial_words</th>\n",
       "      <td>46</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.664</td>\n",
       "      <td>302</td>\n",
       "      <td>31</td>\n",
       "      <td>0.906907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_positive_colloquial_words</th>\n",
       "      <td>47</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.592</td>\n",
       "      <td>276</td>\n",
       "      <td>21</td>\n",
       "      <td>0.929293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           j Polarity  Coverage  Overlaps  \\\n",
       "missing_bio                                0      [1]     0.076     0.076   \n",
       "missing_loc                                1      [1]     0.410     0.410   \n",
       "created_2018_2019                          2      [1]     0.084     0.084   \n",
       "created_2011_2012                          3      [0]     0.288     0.288   \n",
       "bio_keywords                               4      [0]     0.066     0.066   \n",
       "contain_url                                5      [0]     0.044     0.044   \n",
       "contain_mention                            6      [1]     0.652     0.652   \n",
       "labeling_sarcasm                           7      [1]     0.006     0.006   \n",
       "labeling_hate                              8      [1]     0.016     0.016   \n",
       "contain_ent                                9      [1]     0.396     0.396   \n",
       "ent_free                                  10      [0]     0.604     0.604   \n",
       "contain_question                          11      [1]     0.072     0.072   \n",
       "loaded_language                           12      [1]     0.192     0.192   \n",
       "genuine_language                          13      [0]     0.808     0.808   \n",
       "loaded_proppy                             14      [1]     0.034     0.034   \n",
       "genuine_proppy                            15      [0]     0.966     0.966   \n",
       "loaded_hate                               16      [1]     0.034     0.034   \n",
       "loaded_sarcasm                            17      [1]     0.008     0.008   \n",
       "gen_hate                                  18      [0]     0.966     0.966   \n",
       "gen_sarcasm                               19      [0]     0.992     0.992   \n",
       "flag_wave                                 20      [1]     0.150     0.150   \n",
       "repetition                                21      [1]     0.512     0.512   \n",
       "distant_supervision_prop                  22      [1]     0.048     0.048   \n",
       "distant_supervision_gen                   23      [0]     0.126     0.126   \n",
       "slogans                                   24      [1]     0.010     0.010   \n",
       "reductio                                  25      [1]     0.014     0.014   \n",
       "exaggeration                              26      [1]     0.130     0.130   \n",
       "pronouns                                  27      [1]     0.652     0.652   \n",
       "xlmroberta_prop                           28      [1]     0.034     0.034   \n",
       "xlmroberta_gen                            29      [0]     0.120     0.120   \n",
       "loaded_proppy_factives                    30      [1]     0.014     0.014   \n",
       "loaded_proppy_hedges                      31      [1]     0.034     0.034   \n",
       "loaded_proppy_implicatives                32      [1]     0.008     0.008   \n",
       "loaded_proppy_report_verbs                33      [1]     0.054     0.054   \n",
       "loaded_proppy_bias                        34      [1]     0.420     0.420   \n",
       "loaded_proppy_negative_words              35      [1]     0.322     0.322   \n",
       "loaded_proppy_positive_words              36      [1]     0.478     0.478   \n",
       "loaded_proppy_negative_colloquial_words   37      [1]     0.334     0.334   \n",
       "loaded_proppy_positive_colloquial_words   38      [1]     0.406     0.406   \n",
       "genuine_proppy_factives                   39      [0]     0.986     0.986   \n",
       "genuine_proppy_hedges                     40      [0]     0.966     0.966   \n",
       "genuine_proppy_implicatives               41      [0]     0.992     0.992   \n",
       "genuine_proppy_report_verbs               42      [0]     0.946     0.946   \n",
       "genuine_proppy_bias                       43      [0]     0.580     0.580   \n",
       "genuine_proppy_negative_words             44      [0]     0.678     0.678   \n",
       "genuine_proppy_positive_words             45      [0]     0.522     0.522   \n",
       "genuine_proppy_negative_colloquial_words  46      [0]     0.666     0.666   \n",
       "genuine_proppy_positive_colloquial_words  47      [0]     0.594     0.594   \n",
       "\n",
       "                                          Conflicts  Correct  Incorrect  \\\n",
       "missing_bio                                   0.076        3         35   \n",
       "missing_loc                                   0.410       20        185   \n",
       "created_2018_2019                             0.084        3         39   \n",
       "created_2011_2012                             0.288      127         17   \n",
       "bio_keywords                                  0.066       32          1   \n",
       "contain_url                                   0.044       21          1   \n",
       "contain_mention                               0.652       29        297   \n",
       "labeling_sarcasm                              0.006        2          1   \n",
       "labeling_hate                                 0.016        1          7   \n",
       "contain_ent                                   0.396       34        164   \n",
       "ent_free                                      0.602      288         14   \n",
       "contain_question                              0.072       10         26   \n",
       "loaded_language                               0.192       34         62   \n",
       "genuine_language                              0.806      390         14   \n",
       "loaded_proppy                                 0.034        1         16   \n",
       "genuine_proppy                                0.964      436         47   \n",
       "loaded_hate                                   0.034        4         13   \n",
       "loaded_sarcasm                                0.008        3          1   \n",
       "gen_hate                                      0.964      439         44   \n",
       "gen_sarcasm                                   0.990      451         45   \n",
       "flag_wave                                     0.150        7         68   \n",
       "repetition                                    0.512       25        231   \n",
       "distant_supervision_prop                      0.048       11         13   \n",
       "distant_supervision_gen                       0.126       62          1   \n",
       "slogans                                       0.010        3          2   \n",
       "reductio                                      0.014        4          3   \n",
       "exaggeration                                  0.130        8         57   \n",
       "pronouns                                      0.652       36        290   \n",
       "xlmroberta_prop                               0.034        5         12   \n",
       "xlmroberta_gen                                0.120       53          7   \n",
       "loaded_proppy_factives                        0.014        2          5   \n",
       "loaded_proppy_hedges                          0.034        3         14   \n",
       "loaded_proppy_implicatives                    0.008        1          3   \n",
       "loaded_proppy_report_verbs                    0.054        3         24   \n",
       "loaded_proppy_bias                            0.420       32        178   \n",
       "loaded_proppy_negative_words                  0.322       24        137   \n",
       "loaded_proppy_positive_words                  0.478       32        207   \n",
       "loaded_proppy_negative_colloquial_words       0.334       17        150   \n",
       "loaded_proppy_positive_colloquial_words       0.406       27        176   \n",
       "genuine_proppy_factives                       0.984      447         46   \n",
       "genuine_proppy_hedges                         0.964      438         45   \n",
       "genuine_proppy_implicatives                   0.990      449         47   \n",
       "genuine_proppy_report_verbs                   0.944      428         45   \n",
       "genuine_proppy_bias                           0.578      274         16   \n",
       "genuine_proppy_negative_words                 0.676      315         24   \n",
       "genuine_proppy_positive_words                 0.520      245         16   \n",
       "genuine_proppy_negative_colloquial_words      0.664      302         31   \n",
       "genuine_proppy_positive_colloquial_words      0.592      276         21   \n",
       "\n",
       "                                          Emp. Acc.  \n",
       "missing_bio                                0.078947  \n",
       "missing_loc                                0.097561  \n",
       "created_2018_2019                          0.071429  \n",
       "created_2011_2012                          0.881944  \n",
       "bio_keywords                               0.969697  \n",
       "contain_url                                0.954545  \n",
       "contain_mention                            0.088957  \n",
       "labeling_sarcasm                           0.666667  \n",
       "labeling_hate                              0.125000  \n",
       "contain_ent                                0.171717  \n",
       "ent_free                                   0.953642  \n",
       "contain_question                           0.277778  \n",
       "loaded_language                            0.354167  \n",
       "genuine_language                           0.965347  \n",
       "loaded_proppy                              0.058824  \n",
       "genuine_proppy                             0.902692  \n",
       "loaded_hate                                0.235294  \n",
       "loaded_sarcasm                             0.750000  \n",
       "gen_hate                                   0.908903  \n",
       "gen_sarcasm                                0.909274  \n",
       "flag_wave                                  0.093333  \n",
       "repetition                                 0.097656  \n",
       "distant_supervision_prop                   0.458333  \n",
       "distant_supervision_gen                    0.984127  \n",
       "slogans                                    0.600000  \n",
       "reductio                                   0.571429  \n",
       "exaggeration                               0.123077  \n",
       "pronouns                                   0.110429  \n",
       "xlmroberta_prop                            0.294118  \n",
       "xlmroberta_gen                             0.883333  \n",
       "loaded_proppy_factives                     0.285714  \n",
       "loaded_proppy_hedges                       0.176471  \n",
       "loaded_proppy_implicatives                 0.250000  \n",
       "loaded_proppy_report_verbs                 0.111111  \n",
       "loaded_proppy_bias                         0.152381  \n",
       "loaded_proppy_negative_words               0.149068  \n",
       "loaded_proppy_positive_words               0.133891  \n",
       "loaded_proppy_negative_colloquial_words    0.101796  \n",
       "loaded_proppy_positive_colloquial_words    0.133005  \n",
       "genuine_proppy_factives                    0.906694  \n",
       "genuine_proppy_hedges                      0.906832  \n",
       "genuine_proppy_implicatives                0.905242  \n",
       "genuine_proppy_report_verbs                0.904863  \n",
       "genuine_proppy_bias                        0.944828  \n",
       "genuine_proppy_negative_words              0.929204  \n",
       "genuine_proppy_positive_words              0.938697  \n",
       "genuine_proppy_negative_colloquial_words   0.906907  \n",
       "genuine_proppy_positive_colloquial_words   0.929293  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = LFAnalysis(L_dev, lfs).lf_summary(labeled_data.label.values)\n",
    "results.to_json(lfs_analysis_path)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d263b39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195686/195686 [3:46:48<00:00, 14.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_bio</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.068758</td>\n",
       "      <td>0.068758</td>\n",
       "      <td>0.068758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_loc</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.255746</td>\n",
       "      <td>0.255746</td>\n",
       "      <td>0.255746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_2018_2019</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.048532</td>\n",
       "      <td>0.048532</td>\n",
       "      <td>0.048532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_2011_2012</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.371452</td>\n",
       "      <td>0.371452</td>\n",
       "      <td>0.369934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bio_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.326360</td>\n",
       "      <td>0.326360</td>\n",
       "      <td>0.325613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_url</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.461193</td>\n",
       "      <td>0.461193</td>\n",
       "      <td>0.459593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_mention</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.478246</td>\n",
       "      <td>0.478246</td>\n",
       "      <td>0.478246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_sarcasm</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.007773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_hate</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.014881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_ent</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.622962</td>\n",
       "      <td>0.622962</td>\n",
       "      <td>0.622962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_free</th>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.377038</td>\n",
       "      <td>0.377038</td>\n",
       "      <td>0.373972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_question</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.080266</td>\n",
       "      <td>0.080266</td>\n",
       "      <td>0.080266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_language</th>\n",
       "      <td>12</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.225126</td>\n",
       "      <td>0.225126</td>\n",
       "      <td>0.225126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_language</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.774874</td>\n",
       "      <td>0.774874</td>\n",
       "      <td>0.771808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy</th>\n",
       "      <td>14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>0.016179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy</th>\n",
       "      <td>15</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.983821</td>\n",
       "      <td>0.983821</td>\n",
       "      <td>0.980755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_hate</th>\n",
       "      <td>16</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>0.025551</td>\n",
       "      <td>0.025551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_sarcasm</th>\n",
       "      <td>17</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.012111</td>\n",
       "      <td>0.012111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_hate</th>\n",
       "      <td>18</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.974449</td>\n",
       "      <td>0.974449</td>\n",
       "      <td>0.971383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_sarcasm</th>\n",
       "      <td>19</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.987889</td>\n",
       "      <td>0.987889</td>\n",
       "      <td>0.984823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag_wave</th>\n",
       "      <td>20</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.139714</td>\n",
       "      <td>0.139714</td>\n",
       "      <td>0.139714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repetition</th>\n",
       "      <td>21</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.590563</td>\n",
       "      <td>0.590563</td>\n",
       "      <td>0.590563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_prop</th>\n",
       "      <td>22</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.362571</td>\n",
       "      <td>0.362571</td>\n",
       "      <td>0.362571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_gen</th>\n",
       "      <td>23</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.167186</td>\n",
       "      <td>0.167186</td>\n",
       "      <td>0.166915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slogans</th>\n",
       "      <td>24</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>0.005080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reductio</th>\n",
       "      <td>25</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.029542</td>\n",
       "      <td>0.029542</td>\n",
       "      <td>0.029542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exaggeration</th>\n",
       "      <td>26</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.209335</td>\n",
       "      <td>0.209335</td>\n",
       "      <td>0.209335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronouns</th>\n",
       "      <td>27</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.483985</td>\n",
       "      <td>0.483985</td>\n",
       "      <td>0.483985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_prop</th>\n",
       "      <td>28</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.029598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_gen</th>\n",
       "      <td>29</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.124378</td>\n",
       "      <td>0.124378</td>\n",
       "      <td>0.124041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_factives</th>\n",
       "      <td>30</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.021565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_hedges</th>\n",
       "      <td>31</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.047127</td>\n",
       "      <td>0.047127</td>\n",
       "      <td>0.047127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_implicatives</th>\n",
       "      <td>32</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.037310</td>\n",
       "      <td>0.037310</td>\n",
       "      <td>0.037310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_report_verbs</th>\n",
       "      <td>33</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.126570</td>\n",
       "      <td>0.126570</td>\n",
       "      <td>0.126570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_bias</th>\n",
       "      <td>34</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.636014</td>\n",
       "      <td>0.636014</td>\n",
       "      <td>0.636014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_negative_words</th>\n",
       "      <td>35</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.438943</td>\n",
       "      <td>0.438943</td>\n",
       "      <td>0.438943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_positive_words</th>\n",
       "      <td>36</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.624306</td>\n",
       "      <td>0.624306</td>\n",
       "      <td>0.624306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_negative_colloquial_words</th>\n",
       "      <td>37</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.390636</td>\n",
       "      <td>0.390636</td>\n",
       "      <td>0.390636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_positive_colloquial_words</th>\n",
       "      <td>38</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.440348</td>\n",
       "      <td>0.440348</td>\n",
       "      <td>0.440348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_factives</th>\n",
       "      <td>39</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.978435</td>\n",
       "      <td>0.978435</td>\n",
       "      <td>0.975369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_hedges</th>\n",
       "      <td>40</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.952873</td>\n",
       "      <td>0.952873</td>\n",
       "      <td>0.949807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_implicatives</th>\n",
       "      <td>41</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.962690</td>\n",
       "      <td>0.962690</td>\n",
       "      <td>0.959624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_report_verbs</th>\n",
       "      <td>42</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.873430</td>\n",
       "      <td>0.873430</td>\n",
       "      <td>0.870364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_bias</th>\n",
       "      <td>43</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.360920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_negative_words</th>\n",
       "      <td>44</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.561057</td>\n",
       "      <td>0.561057</td>\n",
       "      <td>0.557991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_positive_words</th>\n",
       "      <td>45</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.375694</td>\n",
       "      <td>0.375694</td>\n",
       "      <td>0.372628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_negative_colloquial_words</th>\n",
       "      <td>46</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.606298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy_positive_colloquial_words</th>\n",
       "      <td>47</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.559652</td>\n",
       "      <td>0.559652</td>\n",
       "      <td>0.556586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           j Polarity  Coverage  Overlaps  \\\n",
       "missing_bio                                0      [1]  0.068758  0.068758   \n",
       "missing_loc                                1      [1]  0.255746  0.255746   \n",
       "created_2018_2019                          2      [1]  0.048532  0.048532   \n",
       "created_2011_2012                          3      [0]  0.371452  0.371452   \n",
       "bio_keywords                               4      [0]  0.326360  0.326360   \n",
       "contain_url                                5      [0]  0.461193  0.461193   \n",
       "contain_mention                            6      [1]  0.478246  0.478246   \n",
       "labeling_sarcasm                           7      [1]  0.007773  0.007773   \n",
       "labeling_hate                              8      [1]  0.014881  0.014881   \n",
       "contain_ent                                9      [1]  0.622962  0.622962   \n",
       "ent_free                                  10      [0]  0.377038  0.377038   \n",
       "contain_question                          11      [1]  0.080266  0.080266   \n",
       "loaded_language                           12      [1]  0.225126  0.225126   \n",
       "genuine_language                          13      [0]  0.774874  0.774874   \n",
       "loaded_proppy                             14      [1]  0.016179  0.016179   \n",
       "genuine_proppy                            15      [0]  0.983821  0.983821   \n",
       "loaded_hate                               16      [1]  0.025551  0.025551   \n",
       "loaded_sarcasm                            17      [1]  0.012111  0.012111   \n",
       "gen_hate                                  18      [0]  0.974449  0.974449   \n",
       "gen_sarcasm                               19      [0]  0.987889  0.987889   \n",
       "flag_wave                                 20      [1]  0.139714  0.139714   \n",
       "repetition                                21      [1]  0.590563  0.590563   \n",
       "distant_supervision_prop                  22      [1]  0.362571  0.362571   \n",
       "distant_supervision_gen                   23      [0]  0.167186  0.167186   \n",
       "slogans                                   24      [1]  0.005080  0.005080   \n",
       "reductio                                  25      [1]  0.029542  0.029542   \n",
       "exaggeration                              26      [1]  0.209335  0.209335   \n",
       "pronouns                                  27      [1]  0.483985  0.483985   \n",
       "xlmroberta_prop                           28      [1]  0.029598  0.029598   \n",
       "xlmroberta_gen                            29      [0]  0.124378  0.124378   \n",
       "loaded_proppy_factives                    30      [1]  0.021565  0.021565   \n",
       "loaded_proppy_hedges                      31      [1]  0.047127  0.047127   \n",
       "loaded_proppy_implicatives                32      [1]  0.037310  0.037310   \n",
       "loaded_proppy_report_verbs                33      [1]  0.126570  0.126570   \n",
       "loaded_proppy_bias                        34      [1]  0.636014  0.636014   \n",
       "loaded_proppy_negative_words              35      [1]  0.438943  0.438943   \n",
       "loaded_proppy_positive_words              36      [1]  0.624306  0.624306   \n",
       "loaded_proppy_negative_colloquial_words   37      [1]  0.390636  0.390636   \n",
       "loaded_proppy_positive_colloquial_words   38      [1]  0.440348  0.440348   \n",
       "genuine_proppy_factives                   39      [0]  0.978435  0.978435   \n",
       "genuine_proppy_hedges                     40      [0]  0.952873  0.952873   \n",
       "genuine_proppy_implicatives               41      [0]  0.962690  0.962690   \n",
       "genuine_proppy_report_verbs               42      [0]  0.873430  0.873430   \n",
       "genuine_proppy_bias                       43      [0]  0.363986  0.363986   \n",
       "genuine_proppy_negative_words             44      [0]  0.561057  0.561057   \n",
       "genuine_proppy_positive_words             45      [0]  0.375694  0.375694   \n",
       "genuine_proppy_negative_colloquial_words  46      [0]  0.609364  0.609364   \n",
       "genuine_proppy_positive_colloquial_words  47      [0]  0.559652  0.559652   \n",
       "\n",
       "                                          Conflicts  \n",
       "missing_bio                                0.068758  \n",
       "missing_loc                                0.255746  \n",
       "created_2018_2019                          0.048532  \n",
       "created_2011_2012                          0.369934  \n",
       "bio_keywords                               0.325613  \n",
       "contain_url                                0.459593  \n",
       "contain_mention                            0.478246  \n",
       "labeling_sarcasm                           0.007773  \n",
       "labeling_hate                              0.014881  \n",
       "contain_ent                                0.622962  \n",
       "ent_free                                   0.373972  \n",
       "contain_question                           0.080266  \n",
       "loaded_language                            0.225126  \n",
       "genuine_language                           0.771808  \n",
       "loaded_proppy                              0.016179  \n",
       "genuine_proppy                             0.980755  \n",
       "loaded_hate                                0.025551  \n",
       "loaded_sarcasm                             0.012111  \n",
       "gen_hate                                   0.971383  \n",
       "gen_sarcasm                                0.984823  \n",
       "flag_wave                                  0.139714  \n",
       "repetition                                 0.590563  \n",
       "distant_supervision_prop                   0.362571  \n",
       "distant_supervision_gen                    0.166915  \n",
       "slogans                                    0.005080  \n",
       "reductio                                   0.029542  \n",
       "exaggeration                               0.209335  \n",
       "pronouns                                   0.483985  \n",
       "xlmroberta_prop                            0.029598  \n",
       "xlmroberta_gen                             0.124041  \n",
       "loaded_proppy_factives                     0.021565  \n",
       "loaded_proppy_hedges                       0.047127  \n",
       "loaded_proppy_implicatives                 0.037310  \n",
       "loaded_proppy_report_verbs                 0.126570  \n",
       "loaded_proppy_bias                         0.636014  \n",
       "loaded_proppy_negative_words               0.438943  \n",
       "loaded_proppy_positive_words               0.624306  \n",
       "loaded_proppy_negative_colloquial_words    0.390636  \n",
       "loaded_proppy_positive_colloquial_words    0.440348  \n",
       "genuine_proppy_factives                    0.975369  \n",
       "genuine_proppy_hedges                      0.949807  \n",
       "genuine_proppy_implicatives                0.959624  \n",
       "genuine_proppy_report_verbs                0.870364  \n",
       "genuine_proppy_bias                        0.360920  \n",
       "genuine_proppy_negative_words              0.557991  \n",
       "genuine_proppy_positive_words              0.372628  \n",
       "genuine_proppy_negative_colloquial_words   0.606298  \n",
       "genuine_proppy_positive_colloquial_words   0.556586  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train = applier.apply(unlabeled_data)\n",
    "LFAnalysis(L_train, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b6e06846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 49), (195686, 49))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev_ids = L_dev.copy()\n",
    "L_train_ids = L_train.copy()\n",
    "L_dev_ids= np.append(L_dev_ids, labeled_data.tweetid.to_numpy().reshape(-1, 1), axis=1)\n",
    "L_train_ids= np.append(L_train_ids, unlabeled_data.tweetid.to_numpy().reshape(-1, 1), axis=1)\n",
    "L_dev_ids.shape, L_train_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ded2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(lfs_dev_labels_path, L_dev_ids)\n",
    "np.save(lfs_train_labels_path, L_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e63326e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved data\n",
    "\n",
    "results = pd.read_json(lfs_analysis_path)\n",
    "L_train = np.load(lfs_train_labels_path, allow_pickle=True)\n",
    "L_dev = np.load(lfs_dev_labels_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd172b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_bio</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.076</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_loc</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.410</td>\n",
       "      <td>20</td>\n",
       "      <td>185</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "missing_bio  0      [1]     0.076     0.076      0.076        3         35   \n",
       "missing_loc  1      [1]     0.410     0.410      0.410       20        185   \n",
       "\n",
       "             Emp. Acc.  \n",
       "missing_bio   0.078947  \n",
       "missing_loc   0.097561  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8fb82240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 49), (195686, 49))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.shape, L_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e689eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([503884215260168192, 604045046837465088], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train[:2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d016b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>docs</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>hate</th>\n",
       "      <th>xlmroberta_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>544945186909220864</td>\n",
       "      <td>607579193</td>\n",
       "      <td>Ø­Ù…ÙˆØ¯ Ø§Ù„Ø¯Ø§Ø®Ù„</td>\n",
       "      <td>alntafat</td>\n",
       "      <td>Ø§Ù„Ø±ÙŠØ§Ø¶, Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©</td>\n",
       "      <td>Ù…Ø´ÙŠÙ†Ø§ Ø¹Ù„Ù‰ Ø¯Ø±Ø¨ Ø§Ù„Ù…Ø¹Ø²Ù‡ ÙˆÙ†Ù‡Ø¬ Ø§Ù„Ø¹ÙˆØ¯ ÙˆÙ…Ù† Ù…Ø¯Ø±Ø³Ù‡ Ø´ÙŠØ® ...</td>\n",
       "      <td>61366.0</td>\n",
       "      <td>6869.0</td>\n",
       "      <td>2012-06-13 00:00:00</td>\n",
       "      <td>RT @axxa00: ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ø³ØªØºÙØ±...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9975724816...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99894624...</td>\n",
       "      <td>{'sequence': 'ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117798852772401152.0</td>\n",
       "      <td>2673203522.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>RT @MOISaudiArabia: Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ Ùˆ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© ÙŠØ±Ø¹Ù‰ Ø­Ù...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9980658888...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99932289...</td>\n",
       "      <td>{'sequence': 'Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweetid        userid user_display_name user_screen_name  \\\n",
       "0     544945186909220864     607579193       Ø­Ù…ÙˆØ¯ Ø§Ù„Ø¯Ø§Ø®Ù„         alntafat   \n",
       "1  1117798852772401152.0  2673203522.0              None             None   \n",
       "\n",
       "             user_reported_location  \\\n",
       "0  Ø§Ù„Ø±ÙŠØ§Ø¶, Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©   \n",
       "1                              None   \n",
       "\n",
       "                            user_profile_description  follower_count  \\\n",
       "0  Ù…Ø´ÙŠÙ†Ø§ Ø¹Ù„Ù‰ Ø¯Ø±Ø¨ Ø§Ù„Ù…Ø¹Ø²Ù‡ ÙˆÙ†Ù‡Ø¬ Ø§Ù„Ø¹ÙˆØ¯ ÙˆÙ…Ù† Ù…Ø¯Ø±Ø³Ù‡ Ø´ÙŠØ® ...         61366.0   \n",
       "1                                               None             NaN   \n",
       "\n",
       "   following_count account_creation_date  \\\n",
       "0           6869.0   2012-06-13 00:00:00   \n",
       "1              NaN                   NaT   \n",
       "\n",
       "                                          tweet_text  ...  hashtags  urls  \\\n",
       "0  RT @axxa00: ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ ...  ...         1     0   \n",
       "1  RT @MOISaudiArabia: Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ Ùˆ...  ...         0     1   \n",
       "\n",
       "   user_mentions                                               text  emojis  \\\n",
       "0              1  ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„Ø§ Ø¨Ø§Ù„Ù„Ù‡ Ø§Ø³ØªØºÙØ±...       1   \n",
       "1              1  Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© ÙŠØ±Ø¹Ù‰ Ø­Ù...       0   \n",
       "\n",
       "   word_count                                               docs  \\\n",
       "0          15  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1          13  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                             sarcasm  \\\n",
       "0  {'label': 'Non-Sarcasm', 'score': 0.9975724816...   \n",
       "1  {'label': 'Non-Sarcasm', 'score': 0.9980658888...   \n",
       "\n",
       "                                                hate  \\\n",
       "0  {'label': 'not offensive', 'score': 0.99894624...   \n",
       "1  {'label': 'not offensive', 'score': 0.99932289...   \n",
       "\n",
       "                                    xlmroberta_label  \n",
       "0  {'sequence': 'ØªÙˆÙƒÙ„Øª Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‡ ÙˆÙ„Ø§ Ø­ÙˆÙ„ ÙˆÙ„Ø§Ù‚ÙˆØ© Ø§Ù„...  \n",
       "1  {'sequence': 'Ø§Ù„Ø£Ù…ÙŠØ± Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ² Ø¨Ù† Ø³Ø¹ÙˆØ¯ ÙˆØ²ÙŠØ± Ø§Ù„...  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aeea55a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>docs</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>hate</th>\n",
       "      <th>xlmroberta_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>503884215260168192</td>\n",
       "      <td>551984787</td>\n",
       "      <td>Ø¯. Ø¬ÙˆØ§Ù‡Ø± Ø§Ù„Ø³ÙŠÙâ™›Ø§ØµØ§ÙŠÙ„</td>\n",
       "      <td>Jawaher_ALsaif</td>\n",
       "      <td>London, England</td>\n",
       "      <td>Ø¯ÙƒØªÙˆØ±Ø§Ø© ÙÙŠ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€Û©...</td>\n",
       "      <td>153445.0</td>\n",
       "      <td>3762.0</td>\n",
       "      <td>2012-04-12 00:00:00</td>\n",
       "      <td>RT @a_alswaiyd: Ø±Ø¦ÙŠØ³ Ø§Ù„Ù†ØµØ± ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø­ÙƒØ§Ù… Ø§Ø¬Ø§Ù†Ø¨ Ù…...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø±Ø¦ÙŠØ³ Ø§Ù„Ù†ØµØ± ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø­ÙƒØ§Ù… Ø§Ø¬Ø§Ù†Ø¨ Ù…Ù† Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ù…Ø§Ø¶ÙŠ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Sarcasm', 'score': 0.8988369703292847}</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.98927068...</td>\n",
       "      <td>{'sequence': 'Ø±Ø¦ÙŠØ³ Ø§Ù„Ù†ØµØ± ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø­ÙƒØ§Ù… Ø§Ø¬Ø§Ù†Ø¨ Ù…Ù† ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>604045046837465088</td>\n",
       "      <td>yaERHdZWPYosxTo2yo5Xli7LyNzwBHrVLaCMO5J+a4=</td>\n",
       "      <td>yaERHdZWPYosxTo2yo5Xli7LyNzwBHrVLaCMO5J+a4=</td>\n",
       "      <td>yaERHdZWPYosxTo2yo5Xli7LyNzwBHrVLaCMO5J+a4=</td>\n",
       "      <td>None</td>\n",
       "      <td>â€Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ø¸ÙŠÙ…</td>\n",
       "      <td>4212.0</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>2015-01-08 00:00:00</td>\n",
       "      <td>RT @hashtgareed: #Ø¹Ø§Ø¬Ù„ ğŸ”´\\nÙˆØ¬Ø¯ Ø·ÙÙ„ Ø¶Ø§ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ… Ù...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ø¹Ø§Ø¬Ù„ ÙˆØ¬Ø¯ Ø·ÙÙ„ Ø¶Ø§ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ø´Ø¹ÙŠØ¨Ø© ÙÙŠ Ø¬Ù„Ø§Ø¬Ù„ ÙÙŠ...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9963112473...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99759680...</td>\n",
       "      <td>{'sequence': 'Ø¹Ø§Ø¬Ù„ ÙˆØ¬Ø¯ Ø·ÙÙ„ Ø¶Ø§ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ø´Ø¹ÙŠ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid                                       userid  \\\n",
       "0  503884215260168192                                    551984787   \n",
       "1  604045046837465088  yaERHdZWPYosxTo2yo5Xli7LyNzwBHrVLaCMO5J+a4=   \n",
       "\n",
       "                             user_display_name  \\\n",
       "0                         Ø¯. Ø¬ÙˆØ§Ù‡Ø± Ø§Ù„Ø³ÙŠÙâ™›Ø§ØµØ§ÙŠÙ„   \n",
       "1  yaERHdZWPYosxTo2yo5Xli7LyNzwBHrVLaCMO5J+a4=   \n",
       "\n",
       "                              user_screen_name user_reported_location  \\\n",
       "0                               Jawaher_ALsaif        London, England   \n",
       "1  yaERHdZWPYosxTo2yo5Xli7LyNzwBHrVLaCMO5J+a4=                   None   \n",
       "\n",
       "                            user_profile_description  follower_count  \\\n",
       "0  Ø¯ÙƒØªÙˆØ±Ø§Ø© ÙÙŠ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€Û©...        153445.0   \n",
       "1                                â€Ø§Ø³ØªØºÙØ± Ø§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ø¸ÙŠÙ…          4212.0   \n",
       "\n",
       "   following_count account_creation_date  \\\n",
       "0           3762.0   2012-04-12 00:00:00   \n",
       "1           2843.0   2015-01-08 00:00:00   \n",
       "\n",
       "                                          tweet_text  ...  hashtags  urls  \\\n",
       "0  RT @a_alswaiyd: Ø±Ø¦ÙŠØ³ Ø§Ù„Ù†ØµØ± ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø­ÙƒØ§Ù… Ø§Ø¬Ø§Ù†Ø¨ Ù…...  ...         0     1   \n",
       "1  RT @hashtgareed: #Ø¹Ø§Ø¬Ù„ ğŸ”´\\nÙˆØ¬Ø¯ Ø·ÙÙ„ Ø¶Ø§ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ… Ù...  ...         3     0   \n",
       "\n",
       "   user_mentions                                               text  emojis  \\\n",
       "0              1  Ø±Ø¦ÙŠØ³ Ø§Ù„Ù†ØµØ± ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø­ÙƒØ§Ù… Ø§Ø¬Ø§Ù†Ø¨ Ù…Ù† Ø§Ù„Ù…ÙˆØ³Ù… Ø§Ù„Ù…Ø§Ø¶ÙŠ ...       0   \n",
       "1              1  Ø¹Ø§Ø¬Ù„ ÙˆØ¬Ø¯ Ø·ÙÙ„ Ø¶Ø§ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ø´Ø¹ÙŠØ¨Ø© ÙÙŠ Ø¬Ù„Ø§Ø¬Ù„ ÙÙŠ...       1   \n",
       "\n",
       "   word_count                                               docs  \\\n",
       "0          24  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1          20  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                             sarcasm  \\\n",
       "0  {'label': 'Sarcasm', 'score': 0.8988369703292847}   \n",
       "1  {'label': 'Non-Sarcasm', 'score': 0.9963112473...   \n",
       "\n",
       "                                                hate  \\\n",
       "0  {'label': 'not offensive', 'score': 0.98927068...   \n",
       "1  {'label': 'not offensive', 'score': 0.99759680...   \n",
       "\n",
       "                                    xlmroberta_label  \n",
       "0  {'sequence': 'Ø±Ø¦ÙŠØ³ Ø§Ù„Ù†ØµØ± ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø­ÙƒØ§Ù… Ø§Ø¬Ø§Ù†Ø¨ Ù…Ù† ...  \n",
       "1  {'sequence': 'Ø¹Ø§Ø¬Ù„ ÙˆØ¬Ø¯ Ø·ÙÙ„ Ø¶Ø§ÙŠØ¹ Ø§Ù„ÙŠÙˆÙ… ÙÙŠ Ø§Ù„Ø´Ø¹ÙŠ...  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data = unlabeled_data.set_index(unlabeled_data.tweetid).loc[L_train[:, -1]].reset_index(drop=True)\n",
    "unlabeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2492f4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>...</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>docs</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>hate</th>\n",
       "      <th>xlmroberta_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1091816593032646656</td>\n",
       "      <td>399347336</td>\n",
       "      <td>Ø£Ø¨Ùˆ Ø¹Ø¨Ø¯Ø§Ù„Ù…Ø¬ÙŠØ¯ Ø§Ù„Ø¹Ù…ÙŠÙ…</td>\n",
       "      <td>AAlOmaim</td>\n",
       "      <td>None</td>\n",
       "      <td>Ù…ÙØªØ§Ø¨Ø¹ Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø·Ù‚Ø³ ÙˆÙ…ÙˆØ«Ù‚ Ù„Ù‡Ø§ ÙÙŠ #Ø£Ø±Ø´ÙŠÙ_Ø£Ø¨Ùˆ_Ø¹Ø¨...</td>\n",
       "      <td>18873.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2011-10-27 00:00:00</td>\n",
       "      <td>RT @QX852iVNf3lnJnL85vEdJIwkmC5eZVl7gmFr2ge+G8...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>RT +G8=: Ø­Ø§ÙŠØ± Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© Ù¡Ù¤Ù¤Ù Ù‡Ù€ Ø§Ù„Ø¯ÙŠÙ… ÙˆØ§Ù„Ù†ÙÙŠØ¶ ÙˆØ§Ù„...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9976539015...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99891853...</td>\n",
       "      <td>{'sequence': 'RT +G8=: Ø­Ø§ÙŠØ± Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© Ù¡Ù¤Ù¤Ù Ù‡Ù€ Ø§Ù„Ø¯...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>712221860365205504</td>\n",
       "      <td>2237595005</td>\n",
       "      <td>Ø³Ù€Ù…Ù€Ùˆ Ø§Ù„Ø£Ù…Ù€ÙŠÙ€Ø±</td>\n",
       "      <td>K__S__A__511</td>\n",
       "      <td>â™¥â™¥Ø§Ù„Ù€Ø·Ù€Ø¢Ø¦Ù€ÙÙ€Ù€Û’â™¥â™¥</td>\n",
       "      <td>Ø§Ù„Ø·Ø§ÙŠÙ Ø¯ÙŠØ±Ø© Ø¹Ø´Ù‚ ÙˆØ°ÙƒØ±ÙŠØ§Øª ÙˆÙ…Ù‚Ø§Ø¯ÙŠØ± Ø§Ø¬Ù…Ù„ Ù…Ø§ÙÙŠ Ù…Ø¯Ù† ...</td>\n",
       "      <td>454422.0</td>\n",
       "      <td>98015.0</td>\n",
       "      <td>2013-12-22 00:00:00</td>\n",
       "      <td>-\\n\\nÙ„Ø§ Ø£Ø­Ø¯ ÙŠØ´Ø¹Ø± Ø¨Ø£Ø­Ø¯\\n\\nÙ‡Ø§Ù‡ÙŠ Ø§Ù„Ø´Ù…Ø³ ØªØ­Ø±Ù‚ Ù†ÙØ³Ù‡Ø§...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>- Ù„Ø§ Ø£Ø­Ø¯ ÙŠØ´Ø¹Ø± Ø¨Ø£Ø­Ø¯ Ù‡Ø§Ù‡ÙŠ Ø§Ù„Ø´Ù…Ø³ ØªØ­Ø±Ù‚ Ù†ÙØ³Ù‡Ø§ Ù…Ù† Ø£Ø¬...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'Non-Sarcasm', 'score': 0.9955314993...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99877494...</td>\n",
       "      <td>{'sequence': '- Ù„Ø§ Ø£Ø­Ø¯ ÙŠØ´Ø¹Ø± Ø¨Ø£Ø­Ø¯ Ù‡Ø§Ù‡ÙŠ Ø§Ù„Ø´Ù…Ø³ ØªØ­...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid      userid     user_display_name user_screen_name  \\\n",
       "0  1091816593032646656   399347336  Ø£Ø¨Ùˆ Ø¹Ø¨Ø¯Ø§Ù„Ù…Ø¬ÙŠØ¯ Ø§Ù„Ø¹Ù…ÙŠÙ…         AAlOmaim   \n",
       "1   712221860365205504  2237595005        Ø³Ù€Ù…Ù€Ùˆ Ø§Ù„Ø£Ù…Ù€ÙŠÙ€Ø±     K__S__A__511   \n",
       "\n",
       "  user_reported_location                           user_profile_description  \\\n",
       "0                   None  Ù…ÙØªØ§Ø¨Ø¹ Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø·Ù‚Ø³ ÙˆÙ…ÙˆØ«Ù‚ Ù„Ù‡Ø§ ÙÙŠ #Ø£Ø±Ø´ÙŠÙ_Ø£Ø¨Ùˆ_Ø¹Ø¨...   \n",
       "1       â™¥â™¥Ø§Ù„Ù€Ø·Ù€Ø¢Ø¦Ù€ÙÙ€Ù€Û’â™¥â™¥  Ø§Ù„Ø·Ø§ÙŠÙ Ø¯ÙŠØ±Ø© Ø¹Ø´Ù‚ ÙˆØ°ÙƒØ±ÙŠØ§Øª ÙˆÙ…Ù‚Ø§Ø¯ÙŠØ± Ø§Ø¬Ù…Ù„ Ù…Ø§ÙÙŠ Ù…Ø¯Ù† ...   \n",
       "\n",
       "   follower_count  following_count account_creation_date  \\\n",
       "0         18873.0             93.0   2011-10-27 00:00:00   \n",
       "1        454422.0          98015.0   2013-12-22 00:00:00   \n",
       "\n",
       "                                          tweet_text  ...  urls  \\\n",
       "0  RT @QX852iVNf3lnJnL85vEdJIwkmC5eZVl7gmFr2ge+G8...  ...     0   \n",
       "1  -\\n\\nÙ„Ø§ Ø£Ø­Ø¯ ÙŠØ´Ø¹Ø± Ø¨Ø£Ø­Ø¯\\n\\nÙ‡Ø§Ù‡ÙŠ Ø§Ù„Ø´Ù…Ø³ ØªØ­Ø±Ù‚ Ù†ÙØ³Ù‡Ø§...  ...     0   \n",
       "\n",
       "   user_mentions                                               text emojis  \\\n",
       "0              2  RT +G8=: Ø­Ø§ÙŠØ± Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© Ù¡Ù¤Ù¤Ù Ù‡Ù€ Ø§Ù„Ø¯ÙŠÙ… ÙˆØ§Ù„Ù†ÙÙŠØ¶ ÙˆØ§Ù„...      0   \n",
       "1              0  - Ù„Ø§ Ø£Ø­Ø¯ ÙŠØ´Ø¹Ø± Ø¨Ø£Ø­Ø¯ Ù‡Ø§Ù‡ÙŠ Ø§Ù„Ø´Ù…Ø³ ØªØ­Ø±Ù‚ Ù†ÙØ³Ù‡Ø§ Ù…Ù† Ø£Ø¬...      0   \n",
       "\n",
       "   word_count                                               docs  \\\n",
       "0          20  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1          18  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                             sarcasm  \\\n",
       "0  {'label': 'Non-Sarcasm', 'score': 0.9976539015...   \n",
       "1  {'label': 'Non-Sarcasm', 'score': 0.9955314993...   \n",
       "\n",
       "                                                hate  \\\n",
       "0  {'label': 'not offensive', 'score': 0.99891853...   \n",
       "1  {'label': 'not offensive', 'score': 0.99877494...   \n",
       "\n",
       "                                    xlmroberta_label  label  \n",
       "0  {'sequence': 'RT +G8=: Ø­Ø§ÙŠØ± Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© Ù¡Ù¤Ù¤Ù Ù‡Ù€ Ø§Ù„Ø¯...      0  \n",
       "1  {'sequence': '- Ù„Ø§ Ø£Ø­Ø¯ ÙŠØ´Ø¹Ø± Ø¨Ø£Ø­Ø¯ Ù‡Ø§Ù‡ÙŠ Ø§Ù„Ø´Ù…Ø³ ØªØ­...      0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = labeled_data.set_index(labeled_data.tweetid).loc[L_dev[:, -1]].reset_index(drop=True)\n",
    "labeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b7a35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(unlabeled_data) == len(L_train)\n",
    "assert len(labeled_data) == len(L_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "faace64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = L_train[:, :-1].copy()\n",
    "L_dev = L_dev[:, :-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cc69123a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 48), (195686, 48))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.shape, L_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03fcc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = L_train.astype(np.int32)\n",
    "L_dev = L_dev.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e838a578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the LFs that maximize the performance of the label model\n",
    "flag = ~np.array([results[\"Emp. Acc.\"] < 0.145, results[\"Coverage\"] >= 0.5]).any(axis=0)\n",
    "inds = results[flag].j.to_list()\n",
    "inds.remove(3)\n",
    "inds.append(8)\n",
    "inds.append(13)\n",
    "len(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c32b32c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bio_keywords',\n",
       " 'contain_url',\n",
       " 'labeling_sarcasm',\n",
       " 'contain_ent',\n",
       " 'contain_question',\n",
       " 'loaded_language',\n",
       " 'loaded_hate',\n",
       " 'loaded_sarcasm',\n",
       " 'distant_supervision_prop',\n",
       " 'distant_supervision_gen',\n",
       " 'slogans',\n",
       " 'reductio',\n",
       " 'xlmroberta_prop',\n",
       " 'xlmroberta_gen',\n",
       " 'loaded_proppy_factives',\n",
       " 'loaded_proppy_hedges',\n",
       " 'loaded_proppy_implicatives',\n",
       " 'loaded_proppy_bias',\n",
       " 'loaded_proppy_negative_words',\n",
       " 'labeling_hate',\n",
       " 'genuine_language']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the names of the LFs chosen\n",
    "results.iloc[inds, :].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4f96367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_ = L_train[:, inds].copy()\n",
    "L_dev_ = L_dev[:, inds].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "eb479b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bio_keywords</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.058</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_url</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.026</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_sarcasm</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_ent</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.334</td>\n",
       "      <td>34</td>\n",
       "      <td>164</td>\n",
       "      <td>0.171717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_question</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.054</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_language</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.040</td>\n",
       "      <td>34</td>\n",
       "      <td>62</td>\n",
       "      <td>0.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_hate</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.024</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_sarcasm</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_prop</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.034</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_gen</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.106</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slogans</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reductio</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.006</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_prop</th>\n",
       "      <td>12</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.022</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_gen</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.084</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_factives</th>\n",
       "      <td>14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_hedges</th>\n",
       "      <td>15</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.026</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_implicatives</th>\n",
       "      <td>16</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_bias</th>\n",
       "      <td>17</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.322</td>\n",
       "      <td>32</td>\n",
       "      <td>178</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy_negative_words</th>\n",
       "      <td>18</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.256</td>\n",
       "      <td>24</td>\n",
       "      <td>137</td>\n",
       "      <td>0.149068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_hate</th>\n",
       "      <td>19</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.012</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_language</th>\n",
       "      <td>20</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.582</td>\n",
       "      <td>390</td>\n",
       "      <td>14</td>\n",
       "      <td>0.965347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "bio_keywords                   0      [0]     0.066     0.066      0.058   \n",
       "contain_url                    1      [0]     0.044     0.044      0.026   \n",
       "labeling_sarcasm               2      [1]     0.006     0.006      0.004   \n",
       "contain_ent                    3      [1]     0.396     0.396      0.334   \n",
       "contain_question               4      [1]     0.072     0.072      0.054   \n",
       "loaded_language                5      [1]     0.192     0.176      0.040   \n",
       "loaded_hate                    6      [1]     0.034     0.034      0.024   \n",
       "loaded_sarcasm                 7      [1]     0.008     0.008      0.004   \n",
       "distant_supervision_prop       8      [1]     0.048     0.048      0.034   \n",
       "distant_supervision_gen        9      [0]     0.126     0.126      0.106   \n",
       "slogans                       10      [1]     0.010     0.010      0.008   \n",
       "reductio                      11      [1]     0.014     0.014      0.006   \n",
       "xlmroberta_prop               12      [1]     0.034     0.034      0.022   \n",
       "xlmroberta_gen                13      [0]     0.120     0.120      0.084   \n",
       "loaded_proppy_factives        14      [1]     0.014     0.014      0.012   \n",
       "loaded_proppy_hedges          15      [1]     0.034     0.034      0.026   \n",
       "loaded_proppy_implicatives    16      [1]     0.008     0.008      0.008   \n",
       "loaded_proppy_bias            17      [1]     0.420     0.420      0.322   \n",
       "loaded_proppy_negative_words  18      [1]     0.322     0.322      0.256   \n",
       "labeling_hate                 19      [1]     0.016     0.016      0.012   \n",
       "genuine_language              20      [0]     0.808     0.650      0.582   \n",
       "\n",
       "                              Correct  Incorrect  Emp. Acc.  \n",
       "bio_keywords                       32          1   0.969697  \n",
       "contain_url                        21          1   0.954545  \n",
       "labeling_sarcasm                    2          1   0.666667  \n",
       "contain_ent                        34        164   0.171717  \n",
       "contain_question                   10         26   0.277778  \n",
       "loaded_language                    34         62   0.354167  \n",
       "loaded_hate                         4         13   0.235294  \n",
       "loaded_sarcasm                      3          1   0.750000  \n",
       "distant_supervision_prop           11         13   0.458333  \n",
       "distant_supervision_gen            62          1   0.984127  \n",
       "slogans                             3          2   0.600000  \n",
       "reductio                            4          3   0.571429  \n",
       "xlmroberta_prop                     5         12   0.294118  \n",
       "xlmroberta_gen                     53          7   0.883333  \n",
       "loaded_proppy_factives              2          5   0.285714  \n",
       "loaded_proppy_hedges                3         14   0.176471  \n",
       "loaded_proppy_implicatives          1          3   0.250000  \n",
       "loaded_proppy_bias                 32        178   0.152381  \n",
       "loaded_proppy_negative_words       24        137   0.149068  \n",
       "labeling_hate                       1          7   0.125000  \n",
       "genuine_language                  390         14   0.965347  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_dev_, np.array(lfs)[inds]).lf_summary(labeled_data.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "20b0fe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.904, 0.096]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# estimating the class balance in the unlabeled data from the labeled.\n",
    "\n",
    "w = labeled_data.label.value_counts(normalize=True).to_list()\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c1a5fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e8755fb78742c38a5ad2bbdb4f4769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    }
   ],
   "source": [
    "# tuning the L2 regularization parameter to maximize the performance of the label model\n",
    "# we maximize the precision as it is need to surpass 50% for the noise-aware loss\n",
    "\n",
    "best_score = 0\n",
    "best_model = None\n",
    "l2_values = np.arange(0.0, 0.1, 0.01)\n",
    "\n",
    "\n",
    "metric = \"f1\"\n",
    "for l2 in tqdm(l2_values, total=len(l2_values)):\n",
    "    label_model = LabelModel(cardinality=2, verbose=False, device=\"cuda\")\n",
    "    label_model.fit(\n",
    "        L_train=L_train_,\n",
    "        n_epochs=500,\n",
    "        l2=l2,\n",
    "        lr=0.003,\n",
    "        seed=42,\n",
    "        class_balance=w,\n",
    "        progress_bar=False,\n",
    "        lr_scheduler=\"linear\",\n",
    "        optimizer=\"adamax\",\n",
    "        lr_scheduler_config={\"warmup_percentage\": 0.0, \"warmup_unit\": \"epochs\"},\n",
    "    )\n",
    "    score = label_model.score(L_dev_, labeled_data.label, metrics=[metric])\n",
    "    if score[metric] >= best_score:\n",
    "        best_score = score[metric]\n",
    "        best_model = label_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "3688b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainConfig(n_epochs=500, lr=0.003, l2=0.06, optimizer='adamax', optimizer_config=OptimizerConfig(sgd_config=SGDOptimizerConfig(momentum=0.9), adam_config=AdamOptimizerConfig(amsgrad=False, betas=(0.9, 0.999)), adamax_config=AdamaxOptimizerConfig(betas=(0.9, 0.999), eps=1e-08)), lr_scheduler='linear', lr_scheduler_config=LRSchedulerConfig(warmup_steps=0, warmup_unit='epochs', warmup_percentage=0.0, min_lr=0.0, exponential_config=ExponentialLRSchedulerConfig(gamma=0.9), step_config=StepLRSchedulerConfig(gamma=0.9, step_size=5)), prec_init=0.7, seed=42, log_freq=10, mu_eps=None)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the configs that led to the best label model\n",
    "best_model.train_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042015bd",
   "metadata": {},
   "source": [
    "Reporting the performance of the label model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "4d3fff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.924,\n",
       " 'precision': 0.625,\n",
       " 'recall': 0.5208333333333334,\n",
       " 'f1': 0.5681818181818181,\n",
       " 'f1_macro': 0.7632575757575757,\n",
       " 'f1_micro': 0.924}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(\n",
    "    L_dev_,\n",
    "    labeled_data.label,\n",
    "    tie_break_policy=\"abstain\",\n",
    "    metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"f1_macro\", \"f1_micro\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "927812c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labeled_data.label\n",
    "y_pred = best_model.predict(L_dev_)\n",
    "y_true = y_true[y_pred != -1]\n",
    "y_pred = y_pred[y_pred != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "64acbca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       452\n",
      "           1       0.62      0.52      0.57        48\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.79      0.74      0.76       500\n",
      "weighted avg       0.92      0.92      0.92       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f60bf",
   "metadata": {},
   "source": [
    "Saving the weakly labeled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "062a5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_data[\"snorkel\"] = best_model.predict(L_dev_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "cfb99ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the datasets\n",
    "weak_probs = best_model.predict_proba(L_train_)\n",
    "weak_preds = best_model.predict(L_train_)\n",
    "unlabeled_data[\"label\"] = weak_preds\n",
    "unlabeled_data[\"probs\"] = list(weak_probs)\n",
    "unlabeled_data = unlabeled_data[weak_preds != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "f3a2f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data[[\"tweetid\", \"text\", \"label\", \"probs\"]].to_json(weakly_labeled_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
