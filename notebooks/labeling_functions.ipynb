{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2065b7ef",
   "metadata": {},
   "source": [
    "# Labeling Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3213a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import emoji\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import util\n",
    "\n",
    "from snorkel.preprocess import preprocessor\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8863f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining data paths\n",
    "prop_data_annotated = \"../data/processed/propaganda_annotated.pkl\"\n",
    "gen_data_annotated = \"../data/processed/genuine_annotated.pkl\"\n",
    "wanlp_prop_data_path = \"../data/raw/task1_train.json\"\n",
    "weakly_labeled_data_path = \"../data/processed/train.json\"\n",
    "\n",
    "# we need the lf_dev data to report the performance of LFs\n",
    "# and then remove it with the test data from the unlabaled data\n",
    "lf_dev_data_path = \"../data/processed/lf_dev.json\"\n",
    "test_data_path = \"../data/processed/test_gold.json\"\n",
    "\n",
    "# defining lexicons paths\n",
    "proppy_lex_paths = \"../data/raw/proppy_lexicons/*\"\n",
    "loaded_lex_path = \"../data/raw/loaded-language-lexicons.csv\"\n",
    "\n",
    "# loading pre-trained encoders\n",
    "fasttext_model_path = \"../models/cc.ar.300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1bca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the needed fields by the working labeling functions\n",
    "# in case of doing the analysis from scratch, comment the variable\n",
    "\n",
    "fields = [\n",
    "    \"tweetid\",\n",
    "    \"user_profile_description\",\n",
    "    \"tweet_text\",\n",
    "    \"is_retweet\",\n",
    "    \"quote_count\",\n",
    "    \"reply_count\",\n",
    "    \"like_count\",\n",
    "    \"retweet_count\",\n",
    "    \"hashtags\",\n",
    "    \"urls\",\n",
    "    \"user_mentions\",\n",
    "    \"text\",\n",
    "    \"emojis\",\n",
    "    \"word_count\",\n",
    "    \"docs\",\n",
    "    \"is_irony\",\n",
    "    \"is_hate\",\n",
    "    \"xlmroberta_label\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f9ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(prop_data_annotated)[fields]\n",
    "df2 = pd.read_pickle(gen_data_annotated)[fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following lines handle date conversion\n",
    "\n",
    "df1[\"account_creation_date\"] = pd.to_datetime(df1.account_creation_date, unit=\"ms\")\n",
    "df2[\"account_creation_date\"] = pd.to_datetime(df2.account_creation_date, unit=\"ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c84b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the propaganda and genuine users data\n",
    "\n",
    "unlabeled_data = pd.concat([df1, df2], ignore_index=True)\n",
    "unlabeled_data = unlabeled_data.sample(frac=1.0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150d69b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>docs</th>\n",
       "      <th>is_irony</th>\n",
       "      <th>is_hate</th>\n",
       "      <th>xlmroberta_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1135592977227812865</td>\n",
       "      <td>الأخبـار العاجلة #عاجل مـن مـوقـع جريدة الرياض...</td>\n",
       "      <td>#عاجل:\\nالمحكمة العليا: ثبوت رؤية هلال شوال.. ...</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>110</td>\n",
       "      <td>169.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>عاجل: المحكمة العليا: ثبوت رؤية هلال شوال.. وغ...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.95331501960...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99942123...</td>\n",
       "      <td>{'sequence': 'عاجل: المحكمة العليا: ثبوت رؤية ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1417191564229623808.0</td>\n",
       "      <td>الحساب الرسمي لـ إمارة منطقة القصيم - إنستقرام...</td>\n",
       "      <td>حمد سموه المولى عز وجل على ماتحظى به بلادنا من...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>حمد سموه المولى عز وجل على ماتحظى به بلادنا من...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.94064635038...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99974423...</td>\n",
       "      <td>{'sequence': 'حمد سموه المولى عز وجل على ماتحظ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1263767921010057216.0</td>\n",
       "      <td>الحساب الرسمي للأمن العام السعودي</td>\n",
       "      <td>شرطة القصيم : ضبط مواطنٍ ومقيم استغلّا تصريح ا...</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>شرطة القصيم : ضبط مواطن ومقيم استغلا تصريح الس...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.85628890991...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99958091...</td>\n",
       "      <td>{'sequence': 'شرطة القصيم : ضبط مواطن ومقيم اس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460686542133997573</td>\n",
       "      <td>None</td>\n",
       "      <td>«نزاهة»: ثبوت تورط (20) مواطناً ومقيماً بتعديل...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>«نزاهة»: ثبوت تورط (20) مواطنا ومقيما بتعديل ح...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.74483102560...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99972814...</td>\n",
       "      <td>{'sequence': '«نزاهة»: ثبوت تورط (20) مواطنا و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>870571946106400768</td>\n",
       "      <td>‏‏‎‎#الحرية هي أن تؤمن بها لك ولغيرك\\nلكن تفرض...</td>\n",
       "      <td>RT @hzen2080: ساعات رومانس\\nساعه اوديمار أوتوم...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT : ساعات رومانس ساعه اوديمار أوتوماتيك 650﷼ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.96675294637...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99922728...</td>\n",
       "      <td>{'sequence': 'RT : ساعات رومانس ساعه اوديمار أ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweetid                           user_profile_description  \\\n",
       "0    1135592977227812865  الأخبـار العاجلة #عاجل مـن مـوقـع جريدة الرياض...   \n",
       "1  1417191564229623808.0  الحساب الرسمي لـ إمارة منطقة القصيم - إنستقرام...   \n",
       "2  1263767921010057216.0                  الحساب الرسمي للأمن العام السعودي   \n",
       "3    1460686542133997573                                               None   \n",
       "4     870571946106400768  ‏‏‎‎#الحرية هي أن تؤمن بها لك ولغيرك\\nلكن تفرض...   \n",
       "\n",
       "                                          tweet_text  is_retweet  quote_count  \\\n",
       "0  #عاجل:\\nالمحكمة العليا: ثبوت رؤية هلال شوال.. ...       False         10.0   \n",
       "1  حمد سموه المولى عز وجل على ماتحظى به بلادنا من...       False          0.0   \n",
       "2  شرطة القصيم : ضبط مواطنٍ ومقيم استغلّا تصريح ا...       False          3.0   \n",
       "3  «نزاهة»: ثبوت تورط (20) مواطناً ومقيماً بتعديل...       False          0.0   \n",
       "4  RT @hzen2080: ساعات رومانس\\nساعه اوديمار أوتوم...        True          0.0   \n",
       "\n",
       "   reply_count like_count  retweet_count  hashtags  urls  user_mentions  \\\n",
       "0         16.0        110          169.0         2     1              0   \n",
       "1          3.0       30.0           39.0         4     1              0   \n",
       "2         14.0      157.0          119.0         0     1              0   \n",
       "3          3.0          5            2.0         1     1              0   \n",
       "4          0.0          0            0.0         0     0              1   \n",
       "\n",
       "                                                text  emojis  word_count  \\\n",
       "0  عاجل: المحكمة العليا: ثبوت رؤية هلال شوال.. وغ...       0          17   \n",
       "1  حمد سموه المولى عز وجل على ماتحظى به بلادنا من...       0          35   \n",
       "2  شرطة القصيم : ضبط مواطن ومقيم استغلا تصريح الس...       0          19   \n",
       "3  «نزاهة»: ثبوت تورط (20) مواطنا ومقيما بتعديل ح...       0          40   \n",
       "4  RT : ساعات رومانس ساعه اوديمار أوتوماتيك 650﷼ ...       0          22   \n",
       "\n",
       "                                                docs  \\\n",
       "0  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "2  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "3  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "4  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                            is_irony  \\\n",
       "0  {'label': 'nonsarcasm', 'score': 0.95331501960...   \n",
       "1  {'label': 'nonsarcasm', 'score': 0.94064635038...   \n",
       "2  {'label': 'nonsarcasm', 'score': 0.85628890991...   \n",
       "3  {'label': 'nonsarcasm', 'score': 0.74483102560...   \n",
       "4  {'label': 'nonsarcasm', 'score': 0.96675294637...   \n",
       "\n",
       "                                             is_hate  \\\n",
       "0  {'label': 'not offensive', 'score': 0.99942123...   \n",
       "1  {'label': 'not offensive', 'score': 0.99974423...   \n",
       "2  {'label': 'not offensive', 'score': 0.99958091...   \n",
       "3  {'label': 'not offensive', 'score': 0.99972814...   \n",
       "4  {'label': 'not offensive', 'score': 0.99922728...   \n",
       "\n",
       "                                    xlmroberta_label  \n",
       "0  {'sequence': 'عاجل: المحكمة العليا: ثبوت رؤية ...  \n",
       "1  {'sequence': 'حمد سموه المولى عز وجل على ماتحظ...  \n",
       "2  {'sequence': 'شرطة القصيم : ضبط مواطن ومقيم اس...  \n",
       "3  {'sequence': '«نزاهة»: ثبوت تورط (20) مواطنا و...  \n",
       "4  {'sequence': 'RT : ساعات رومانس ساعه اوديمار أ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d7564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196612 entries, 0 to 196611\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   tweetid                   196610 non-null  object \n",
      " 1   user_profile_description  183084 non-null  object \n",
      " 2   tweet_text                196612 non-null  object \n",
      " 3   is_retweet                196612 non-null  bool   \n",
      " 4   quote_count               196607 non-null  float64\n",
      " 5   reply_count               196608 non-null  float64\n",
      " 6   like_count                196608 non-null  object \n",
      " 7   retweet_count             196608 non-null  float64\n",
      " 8   hashtags                  196612 non-null  int64  \n",
      " 9   urls                      196612 non-null  int64  \n",
      " 10  user_mentions             196612 non-null  int64  \n",
      " 11  text                      196612 non-null  object \n",
      " 12  emojis                    196612 non-null  int64  \n",
      " 13  word_count                196612 non-null  int64  \n",
      " 14  docs                      196612 non-null  object \n",
      " 15  is_irony                  196612 non-null  object \n",
      " 16  is_hate                   196612 non-null  object \n",
      " 17  xlmroberta_label          196611 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(5), object(9)\n",
      "memory usage: 25.7+ MB\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbd4c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>text</th>\n",
       "      <th>tech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>924924839902793728</td>\n",
       "      <td>RT @Amal_onzi: 🕊💕هُو جنْةبعِيني.</td>\n",
       "      <td>RT : هو جنةبعيني.</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1074734231887187968</td>\n",
       "      <td>ر٣ #تركيا_تجاهر_بالمعاصي</td>\n",
       "      <td>ر٣ تركيا تجاهر بالمعاصي</td>\n",
       "      <td>smears - name-calling - loaded language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1089924333378682880</td>\n",
       "      <td>RT @al_raqi_8: 💝 طقم نسائي  حصيره شكل  ديور مغ...</td>\n",
       "      <td>RT : طقم نسائي حصيره شكل ديور مغناطيس ١ *ساعه ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>752398332270563328</td>\n",
       "      <td>RT @vvvv1l: اصحو ي ناس 👊\\n\\n #الثوره_الخمينيه_...</td>\n",
       "      <td>RT : اصحو ي ناس الثوره الخمينيه تتمزق</td>\n",
       "      <td>loaded language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1079749279089078272</td>\n",
       "      <td>RT @rood516: اطقم نسائيه من ماركة رولكس😍✨1\\nسا...</td>\n",
       "      <td>RT : اطقم نسائيه من ماركة رولكس1 ساعه نسائيه م...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                         tweet_text  \\\n",
       "0   924924839902793728                   RT @Amal_onzi: 🕊💕هُو جنْةبعِيني.   \n",
       "1  1074734231887187968                           ر٣ #تركيا_تجاهر_بالمعاصي   \n",
       "2  1089924333378682880  RT @al_raqi_8: 💝 طقم نسائي  حصيره شكل  ديور مغ...   \n",
       "3   752398332270563328  RT @vvvv1l: اصحو ي ناس 👊\\n\\n #الثوره_الخمينيه_...   \n",
       "4  1079749279089078272  RT @rood516: اطقم نسائيه من ماركة رولكس😍✨1\\nسا...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                  RT : هو جنةبعيني.   \n",
       "1                            ر٣ تركيا تجاهر بالمعاصي   \n",
       "2  RT : طقم نسائي حصيره شكل ديور مغناطيس ١ *ساعه ...   \n",
       "3              RT : اصحو ي ناس الثوره الخمينيه تتمزق   \n",
       "4  RT : اطقم نسائيه من ماركة رولكس1 ساعه نسائيه م...   \n",
       "\n",
       "                                      tech  label  \n",
       "0                                     None      0  \n",
       "1  smears - name-calling - loaded language      1  \n",
       "2                                     None      0  \n",
       "3                          loaded language      1  \n",
       "4                                     None      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = pd.read_json(lf_dev_data_path)\n",
    "labeled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc6ee7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 0 to 499\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweetid     500 non-null    int64 \n",
      " 1   tweet_text  500 non-null    object\n",
      " 2   text        500 non-null    object\n",
      " 3   tech        48 non-null     object\n",
      " 4   label       500 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 23.4+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(test_data_path)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3beb4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user_profile_description</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>word_count</th>\n",
       "      <th>docs</th>\n",
       "      <th>is_irony</th>\n",
       "      <th>is_hate</th>\n",
       "      <th>xlmroberta_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>841000033365446656</td>\n",
       "      <td>دام ابوي حولي ما علي خلاف.</td>\n",
       "      <td>يااخي اول شي اجابته صح ثاني شي في اجابه خطا لع...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>يااخي اول شي اجابته صح ثاني شي في اجابه خطا لع...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.53657037019...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99910682...</td>\n",
       "      <td>{'sequence': 'يااخي اول شي اجابته صح ثاني شي ف...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>862407267840393216</td>\n",
       "      <td>شوي من هنا وشويتين من هناك...سياسة ومجتمع وشعر...</td>\n",
       "      <td>الا غصب تشتري 😂😂 https://t.co/cbVH13bh6J</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>الا غصب تشتري</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.68531942367...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99869710...</td>\n",
       "      <td>{'sequence': 'الا غصب تشتري', 'labels': ['tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>683277968156798976</td>\n",
       "      <td>‏‏‏(رب اغفر لي ولوالدي ولمن دخل بيتي مؤمناً ول...</td>\n",
       "      <td>RT @aldmgane: لم أشجع الهلال باحثاً عن رضاكم،\\...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT : لم أشجع الهلال باحثا عن رضاكم، ولم أمتدحه...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.92064410448...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99944049...</td>\n",
       "      <td>{'sequence': 'RT : لم أشجع الهلال باحثا عن رضا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1026259146000228352</td>\n",
       "      <td>‏‏‎‎#الحرية هي أن تؤمن بها لك ولغيرك\\nلكن تفرض...</td>\n",
       "      <td>RT @ksavi1p: أول مرة أشوف هذا الفديو من هذه ال...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT : أول مرة أشوف هذا الفديو من هذه الزاوية</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.75664991140...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99878746...</td>\n",
       "      <td>{'sequence': 'RT : أول مرة أشوف هذا الفديو من ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1069588123846356992</td>\n",
       "      <td>من قال اني لا ابوح ؟! قد أخبرت ربي كل شيء !!</td>\n",
       "      <td>#استقبال_مليوني\\n اللهم اجعلنا اوفر عبادك حظا ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>استقبال مليوني اللهم اجعلنا اوفر عبادك حظا في ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>{'label': 'nonsarcasm', 'score': 0.95686054229...</td>\n",
       "      <td>{'label': 'not offensive', 'score': 0.99981170...</td>\n",
       "      <td>{'sequence': 'استقبال مليوني اللهم اجعلنا اوفر...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweetid                           user_profile_description  \\\n",
       "318    841000033365446656                         دام ابوي حولي ما علي خلاف.   \n",
       "373    862407267840393216  شوي من هنا وشويتين من هناك...سياسة ومجتمع وشعر...   \n",
       "390    683277968156798976  ‏‏‏(رب اغفر لي ولوالدي ولمن دخل بيتي مؤمناً ول...   \n",
       "652   1026259146000228352  ‏‏‎‎#الحرية هي أن تؤمن بها لك ولغيرك\\nلكن تفرض...   \n",
       "1467  1069588123846356992       من قال اني لا ابوح ؟! قد أخبرت ربي كل شيء !!   \n",
       "\n",
       "                                             tweet_text  is_retweet  \\\n",
       "318   يااخي اول شي اجابته صح ثاني شي في اجابه خطا لع...       False   \n",
       "373            الا غصب تشتري 😂😂 https://t.co/cbVH13bh6J       False   \n",
       "390   RT @aldmgane: لم أشجع الهلال باحثاً عن رضاكم،\\...        True   \n",
       "652   RT @ksavi1p: أول مرة أشوف هذا الفديو من هذه ال...        True   \n",
       "1467  #استقبال_مليوني\\n اللهم اجعلنا اوفر عبادك حظا ...       False   \n",
       "\n",
       "      quote_count  reply_count like_count  retweet_count  hashtags  urls  \\\n",
       "318           0.0          0.0          0            0.0         1     0   \n",
       "373           0.0          0.0          0            0.0         0     0   \n",
       "390           0.0          0.0          0            0.0         0     0   \n",
       "652           0.0          0.0          0            0.0         0     0   \n",
       "1467          0.0          0.0          0            0.0         1     0   \n",
       "\n",
       "      user_mentions                                               text  \\\n",
       "318               3  يااخي اول شي اجابته صح ثاني شي في اجابه خطا لع...   \n",
       "373               0                                      الا غصب تشتري   \n",
       "390               1  RT : لم أشجع الهلال باحثا عن رضاكم، ولم أمتدحه...   \n",
       "652               1        RT : أول مرة أشوف هذا الفديو من هذه الزاوية   \n",
       "1467              0  استقبال مليوني اللهم اجعلنا اوفر عبادك حظا في ...   \n",
       "\n",
       "      emojis  word_count                                               docs  \\\n",
       "318        0          19  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "373        2           3  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "390        0          24  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "652        7          10  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "1467       0          11  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...   \n",
       "\n",
       "                                               is_irony  \\\n",
       "318   {'label': 'nonsarcasm', 'score': 0.53657037019...   \n",
       "373   {'label': 'nonsarcasm', 'score': 0.68531942367...   \n",
       "390   {'label': 'nonsarcasm', 'score': 0.92064410448...   \n",
       "652   {'label': 'nonsarcasm', 'score': 0.75664991140...   \n",
       "1467  {'label': 'nonsarcasm', 'score': 0.95686054229...   \n",
       "\n",
       "                                                is_hate  \\\n",
       "318   {'label': 'not offensive', 'score': 0.99910682...   \n",
       "373   {'label': 'not offensive', 'score': 0.99869710...   \n",
       "390   {'label': 'not offensive', 'score': 0.99944049...   \n",
       "652   {'label': 'not offensive', 'score': 0.99878746...   \n",
       "1467  {'label': 'not offensive', 'score': 0.99981170...   \n",
       "\n",
       "                                       xlmroberta_label  \n",
       "318   {'sequence': 'يااخي اول شي اجابته صح ثاني شي ف...  \n",
       "373   {'sequence': 'الا غصب تشتري', 'labels': ['tran...  \n",
       "390   {'sequence': 'RT : لم أشجع الهلال باحثا عن رضا...  \n",
       "652   {'sequence': 'RT : أول مرة أشوف هذا الفديو من ...  \n",
       "1467  {'sequence': 'استقبال مليوني اللهم اجعلنا اوفر...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = unlabeled_data[unlabeled_data.text.isin(labeled.text)]\n",
    "labeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9f6f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 318 to 196598\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   tweetid                   500 non-null    object \n",
      " 1   user_profile_description  462 non-null    object \n",
      " 2   tweet_text                500 non-null    object \n",
      " 3   is_retweet                500 non-null    bool   \n",
      " 4   quote_count               500 non-null    float64\n",
      " 5   reply_count               500 non-null    float64\n",
      " 6   like_count                500 non-null    object \n",
      " 7   retweet_count             500 non-null    float64\n",
      " 8   hashtags                  500 non-null    int64  \n",
      " 9   urls                      500 non-null    int64  \n",
      " 10  user_mentions             500 non-null    int64  \n",
      " 11  text                      500 non-null    object \n",
      " 12  emojis                    500 non-null    int64  \n",
      " 13  word_count                500 non-null    int64  \n",
      " 14  docs                      500 non-null    object \n",
      " 15  is_irony                  500 non-null    object \n",
      " 16  is_hate                   500 non-null    object \n",
      " 17  xlmroberta_label          500 non-null    object \n",
      "dtypes: bool(1), float64(3), int64(5), object(9)\n",
      "memory usage: 70.8+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d90e2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the labeled tweets from the unlabeled data\n",
    "\n",
    "unlabeled_data = unlabeled_data[~unlabeled_data.text.isin(labeled_data.text)]\n",
    "unlabeled_data = unlabeled_data[~unlabeled_data.text.isin(test.text)]\n",
    "unlabeled_data = unlabeled_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = labeled_data.reset_index(drop=True)\n",
    "labels = [labeled[labeled.text == i].label.values[0] for i in labeled_data.text]\n",
    "labeled_data[\"label\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "962055c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure the dataset doesn't contain any null values\n",
    "\n",
    "subset = [\"tweetid\", \"text\", \"quote_count\", \"xlmroberta_label\"]\n",
    "unlabeled_data = unlabeled_data.dropna(subset=subset)\n",
    "unlabeled_data = unlabeled_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45b9a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196106 entries, 0 to 196105\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   tweetid                   196106 non-null  object \n",
      " 1   user_profile_description  182621 non-null  object \n",
      " 2   tweet_text                196106 non-null  object \n",
      " 3   is_retweet                196106 non-null  bool   \n",
      " 4   quote_count               196106 non-null  float64\n",
      " 5   reply_count               196106 non-null  float64\n",
      " 6   like_count                196106 non-null  object \n",
      " 7   retweet_count             196106 non-null  float64\n",
      " 8   hashtags                  196106 non-null  int64  \n",
      " 9   urls                      196106 non-null  int64  \n",
      " 10  user_mentions             196106 non-null  int64  \n",
      " 11  text                      196106 non-null  object \n",
      " 12  emojis                    196106 non-null  int64  \n",
      " 13  word_count                196106 non-null  int64  \n",
      " 14  docs                      196106 non-null  object \n",
      " 15  is_irony                  196106 non-null  object \n",
      " 16  is_hate                   196106 non-null  object \n",
      " 17  xlmroberta_label          196106 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(5), object(9)\n",
      "memory usage: 25.6+ MB\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f118b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   tweetid                   500 non-null    object \n",
      " 1   user_profile_description  462 non-null    object \n",
      " 2   tweet_text                500 non-null    object \n",
      " 3   is_retweet                500 non-null    bool   \n",
      " 4   quote_count               500 non-null    float64\n",
      " 5   reply_count               500 non-null    float64\n",
      " 6   like_count                500 non-null    object \n",
      " 7   retweet_count             500 non-null    float64\n",
      " 8   hashtags                  500 non-null    int64  \n",
      " 9   urls                      500 non-null    int64  \n",
      " 10  user_mentions             500 non-null    int64  \n",
      " 11  text                      500 non-null    object \n",
      " 12  emojis                    500 non-null    int64  \n",
      " 13  word_count                500 non-null    int64  \n",
      " 14  docs                      500 non-null    object \n",
      " 15  is_irony                  500 non-null    object \n",
      " 16  is_hate                   500 non-null    object \n",
      " 17  xlmroberta_label          500 non-null    object \n",
      " 18  label                     500 non-null    int64  \n",
      "dtypes: bool(1), float64(3), int64(6), object(9)\n",
      "memory usage: 70.9+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3182d",
   "metadata": {},
   "source": [
    "### User LFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a17d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = 1\n",
    "gen = 0\n",
    "ab = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9451286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def missing_bio(example):\n",
    "    \"\"\"Label all tweets of a user as propaganda if they don't have a bio.\"\"\"\n",
    "    if pd.isna(example.user_profile_description):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b9b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def missing_loc(example):\n",
    "    \"\"\"Label all tweets of a user as propaganda if they don't have a location.\"\"\"\n",
    "    if pd.isna(example.user_reported_location):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b852b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def created_2018_2019(example):\n",
    "    \"\"\"Label all tweets of a user as propaganda if account is created 2018 or 2019.\"\"\"\n",
    "    if example.account_creation_date.year in [2018, 2019]:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8077985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def created_2011_2012(example):\n",
    "    \"\"\"Label all tweets of a user as transparent if account is created 2011 or 2012.\"\"\"\n",
    "    if example.account_creation_date.year in [2011, 2012]:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "112fc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor(memoize=False)\n",
    "def tokenize_bio(example):\n",
    "    \"\"\"Tokenize text in the bio.\"\"\"\n",
    "    if not pd.isna(example.user_profile_description):\n",
    "        example.bio_tokens = word_tokenize(example.user_profile_description)\n",
    "    else:\n",
    "        example.bio_tokens = None\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "655f9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[tokenize_bio])\n",
    "def bio_keywords(example):\n",
    "    \"\"\"Label all tweets of a user as transparent if bio contains certain lexicons.\"\"\"\n",
    "    keys = [\"الحساب\", \"الرسمي\", \"عضو\", \"رئيس\", \"كاتب\", \"إدارة\"]\n",
    "    if example.bio_tokens is not None:\n",
    "        if any(np.in1d(keys, example.bio_tokens)):\n",
    "            return gen\n",
    "        else:\n",
    "            return ab\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e8431",
   "metadata": {},
   "source": [
    "### Tweet LFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba3b58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_url(example):\n",
    "    \"\"\"Label tweet as transparent if it contains a URL.\"\"\"\n",
    "    if example.urls > 0:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dd1562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_mention(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains a mention.\"\"\"\n",
    "    if example.user_mentions > 0:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ae1e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def labeling_sarcasm(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains the name calling tech (sarcasm).\"\"\"\n",
    "    if len(example.docs.entities) and example.sarcasm[\"label\"] == \"Sarcasm\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "066eae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def labeling_hate(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains the name calling tech (hate).\"\"\"\n",
    "    if len(example.docs.entities) and example.hate[\"label\"] == \"offensive\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a797ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_ent(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains an entity.\"\"\"\n",
    "    if len(example.docs.entities):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daff9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def ent_free(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain any entities.\"\"\"\n",
    "    if len(example.docs.entities):\n",
    "        return ab\n",
    "    else:\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df8bbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contain_question(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains an question.\"\"\"\n",
    "    for w in example.docs.sentences[0].words:\n",
    "        if w.upos == \"AUX\":\n",
    "            return prop\n",
    "    return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91695adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['جاهر', 'جهر', 'تجاهر بالمعاصي', 'مجاهرة بالمعاصي', 'تجاهر بالمعاصى']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the manually crafted loaded tokens.\n",
    "# extracted only from the 500 tweets used for labeling functions development.\n",
    "\n",
    "loaded_lexicons = pd.read_csv(loaded_lex_path)[\"loaded-language\"].to_list()\n",
    "loaded_lexicons[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44dbade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the proppy lexicons introduced in https://arxiv.org/abs/1912.06810\n",
    "\n",
    "proppy_lexicons = []\n",
    "for file in glob.glob(proppy_lex_paths):\n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        proppy_lexicons.extend(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04d43494",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# removing diacritization from proppy lexicons\n",
    "\n",
    "pattern = r\"[\\u0617-\\u061A\\u064B-\\u0652]\"\n",
    "proppy_lexicons = [re.sub(pattern, \"\", term.strip()) for term in proppy_lexicons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23b939c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['إجهاض', 'إساءة', 'تعسفي', 'يقبل', 'حساب']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proppy_lexicons[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7fd6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor(memoize=False)\n",
    "def tokenize_tweet(example):\n",
    "    \"\"\"Tokenize and lemmatize text in tweets.\"\"\"\n",
    "    if len(example.docs.sentences):\n",
    "        example.tweet_tokens = [w.text for w in example.docs.sentences[0].words]\n",
    "        example.tweet_lemmas = [w.lemma for w in example.docs.sentences[0].words]\n",
    "    else:\n",
    "        example.tweet_tokens = []\n",
    "        example.tweet_lemmas = []\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3364bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor(pre=[tokenize_tweet], memoize=False)\n",
    "def bigram_tweet(example):\n",
    "    \"\"\"Create bigrams of tweet text's tokens and lemmas.\"\"\"\n",
    "    example.bigram_tokens = [\n",
    "        \" \".join(gram) for gram in ngrams(example.tweet_tokens, 2) if len(gram)\n",
    "    ]\n",
    "    example.bigram_lemmas = [\n",
    "        \" \".join(gram) for gram in ngrams(example.tweet_lemmas, 2) if len(gram)\n",
    "    ]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c61587df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def loaded_language(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains any of the loaded lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, loaded_lexicons)) >= 1:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f41749df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])  # [bigram_tweet]\n",
    "def genuine_language(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain any of the loaded lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, loaded_lexicons)) == 0:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def loaded_proppy(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains any of the proppy lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, proppy_lexicons)) >= 1:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa443bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def genuine_proppy(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain any of the proppy lexicons.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if sum(np.in1d(tweet_ngrams, proppy_lexicons)) == 0:\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a064cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def loaded_hate(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains hate speech (loaded language).\"\"\"\n",
    "    if example.hate[\"label\"] == \"offensive\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da906bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def loaded_sarcasm(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains sarcasm (loaded language).\"\"\"\n",
    "    if example.sarcasm[\"label\"] == \"Sarcasm\":\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47a41f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def gen_hate(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain hate speech (loaded language).\"\"\"\n",
    "    if example.hate[\"label\"] == \"not offensive\":\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "095a3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def gen_sarcasm(example):\n",
    "    \"\"\"Label tweet as transparent if it doesn't contain sarcasm (loaded language).\"\"\"\n",
    "    if example.sarcasm[\"label\"] == \"Non-Sarcasm\":\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c73753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag_waving\n",
    "\n",
    "flag_engine = re.compile(r\"Number=\\w+\")\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def flag_wave(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains plural pronouns (flag-waving).\"\"\"\n",
    "    for w in example.docs.sentences[0].words:\n",
    "        if (\n",
    "            w.upos == \"PRON\"\n",
    "            and flag_engine.findall(w.feats)[0].split(\"=\")[-1] == \"Plur\"\n",
    "        ):\n",
    "            return prop\n",
    "    return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4437bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Arabic NLTK stop words.\n",
    "arabic_stop_words = stopwords.words(\"arabic\")\n",
    "\n",
    "# removing diacritization from stop words\n",
    "pattern = r\"[\\u0617-\\u061A\\u064B-\\u0652]\"\n",
    "arabic_stop_words = [re.sub(pattern, \"\", w) for w in arabic_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efebd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[tokenize_tweet])\n",
    "def repetition(example):\n",
    "    \"\"\"Label tweet as propaganda if it has at least one repeated token.\"\"\"\n",
    "    tokens = [word for word in example.tweet_tokens if word not in arabic_stop_words]\n",
    "    tokens = pd.Series(tokens)\n",
    "    if tokens.value_counts().max() >= 2:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0306bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1358824915483435008</td>\n",
       "      <td>#بي_بي_سي_ترندينغ: النساء \"تثرثر كثيرا\" رئيس أ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1389927866356412416</td>\n",
       "      <td>\"ده مش معتقل ده أحسن من اللوكاندة\".. جدل وسخري...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1364082975428677632</td>\n",
       "      <td>الرجل الذي كان من فراغ https://t.co/2bnHiRqGRQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391667689656102912</td>\n",
       "      <td>RT @AJABreaking: عاجل | حركة حماس: ما يجري في ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1389360446440972288</td>\n",
       "      <td>انطلاق أسبوع المرور العربي تحت شعار: \"الحوادث ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1358824915483435008  #بي_بي_سي_ترندينغ: النساء \"تثرثر كثيرا\" رئيس أ...   \n",
       "1  1389927866356412416  \"ده مش معتقل ده أحسن من اللوكاندة\".. جدل وسخري...   \n",
       "2  1364082975428677632     الرجل الذي كان من فراغ https://t.co/2bnHiRqGRQ   \n",
       "3  1391667689656102912  RT @AJABreaking: عاجل | حركة حماس: ما يجري في ...   \n",
       "4  1389360446440972288  انطلاق أسبوع المرور العربي تحت شعار: \"الحوادث ...   \n",
       "\n",
       "   labels  \n",
       "0       0  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the WANLP propaganda dataset for distant supervision\n",
    "# dataset source: https://gitlab.com/araieval/propaganda-detection\n",
    "\n",
    "\n",
    "wanlp_train = pd.read_json(wanlp_prop_data_path)\n",
    "\n",
    "label_processing = lambda x: 0 if \"no technique\" in x else 1\n",
    "wanlp_train[\"labels\"] = wanlp_train[\"labels\"].apply(label_processing)\n",
    "\n",
    "wanlp_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f74bfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Process text and remove links, symbols, and diacritization.\"\"\"\n",
    "    # links\n",
    "    clean_text = re.sub(r\"http\\S+|t\\.co/\\S+\", \"\", text)\n",
    "    # mentions\n",
    "    clean_text = re.sub(r\"@\\w+\", \"\", clean_text)\n",
    "    # hashtags\n",
    "    clean_text = re.sub(r\"#\", \"\", clean_text)\n",
    "    clean_text = re.sub(r\"_\", \" \", clean_text)\n",
    "    # tashqeel - from @bakriano\n",
    "    clean_text = re.sub(r\"[\\u0617-\\u061A\\u064B-\\u0652]\", \"\", clean_text)\n",
    "    # emojis\n",
    "    clean_text = emoji.replace_emoji(clean_text, replace=\"\")\n",
    "    # remove new lines and normalize white spaces\n",
    "    clean_text = re.sub(r\"\\s+\", \" \", clean_text)\n",
    "    return clean_text.replace(\"RT :\", \"\").strip()\n",
    "\n",
    "\n",
    "wanlp_train[\"text\"] = wanlp_train[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50aac88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625a35f268ad45ed9fc876dfa8da4769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = fasttext.load_model(fasttext_model_path)\n",
    "\n",
    "wanlp_hidden_states = []\n",
    "for tweet in tqdm(wanlp_train.text.values, total=len(wanlp_train)):\n",
    "    vec = encoder.get_sentence_vector(tweet)\n",
    "    wanlp_hidden_states.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@preprocessor()\n",
    "def get_sim_scores(example):\n",
    "    \"\"\"Get similarity score between tweet and WANLP propaganda tweets.\"\"\"\n",
    "    tweet_vec = encoder.get_sentence_vector(example.text)\n",
    "    sim_scores = util.cos_sim(tweet_vec, wanlp_hidden_states)\n",
    "    example.sim_scores = sim_scores\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8106c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function(pre=[get_sim_scores])\n",
    "def distant_supervision_prop(example):\n",
    "    \"\"\"Label tweet as propaganda based on its most similar WANLP example.\"\"\"\n",
    "    sim_scores = example.sim_scores\n",
    "    most_sim = sim_scores.argmax(dim=-1).item()\n",
    "    if (\n",
    "        wanlp_train.labels.values[most_sim] == 1\n",
    "        and sim_scores[-1][most_sim].item() >= 0.75\n",
    "    ):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b25f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function(pre=[get_sim_scores])\n",
    "def distant_supervision_gen(example):\n",
    "    \"\"\"Label tweet as transparent based on its most similar WANLP example.\"\"\"\n",
    "    sim_scores = example.sim_scores\n",
    "    most_sim = sim_scores.argmax(dim=-1).item()\n",
    "    if (\n",
    "        wanlp_train.labels.values[most_sim] == 0\n",
    "        and sim_scores[-1][most_sim].item() >= 0.65\n",
    "    ):\n",
    "        return gen\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0957a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def slogans(example):\n",
    "    \"\"\"Label tweet as propaganda if it has any of the slogans form.\"\"\"\n",
    "    matches = re.findall(r\"لا ل\\w+\", example.text)\n",
    "    matches += re.findall(r\"نعم ل\\w+\", example.text)\n",
    "    matches += re.findall(r\"لا بديل\", example.text)\n",
    "    if len(matches):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c42d91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the manually extracted hated organizations and entities.\n",
    "\n",
    "hitlerum = [\n",
    "    \"هتلر\",\n",
    "    \"البغدادي\",\n",
    "    \"اوردوغان\",\n",
    "    \"قطر\",\n",
    "    \"داعش\",\n",
    "    \"حوثي\",\n",
    "    \"تركيا\",\n",
    "    \"الشيعة\",\n",
    "    \"إيران\",\n",
    "    \"ايران\",\n",
    "    \"اخونجي\",\n",
    "    \"اخوان\",\n",
    "    \"إخوان\",\n",
    "    \"إخوانجي\",\n",
    "    \"أوردوغان\",\n",
    "    \"الحوثي\",\n",
    "    \"الحوثيين\",\n",
    "    \"ستالين\",\n",
    "    \"الإخوان\",\n",
    "    \"الاخوان\",\n",
    "    \"إرهابي\",\n",
    "    \"الإرهابيين\",\n",
    "    \"متطرف\",\n",
    "    \"المتطرفين\",\n",
    "    \"شيعي\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f9c8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[bigram_tweet])\n",
    "def reductio(example):\n",
    "    \"\"\"Label tweet as propaganda if it contains the Reductio Ad Hitlerum tech.\"\"\"\n",
    "    tweet_ngrams = example.tweet_tokens + example.tweet_lemmas\n",
    "    tweet_ngrams += example.bigram_tokens + example.bigram_lemmas\n",
    "    if any(np.in1d(tweet_ngrams, hitlerum)):\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3af0650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def exaggeration(example):\n",
    "    \"\"\"Label tweet as propaganda if has the \"أفعل\" preference form.\"\"\"\n",
    "    if not len(example.docs.sentences):\n",
    "        return ab\n",
    "    for w in example.docs.sentences[0].words:\n",
    "        if w.lemma.startswith(\"أ\") and w.upos == \"ADJ\":\n",
    "            return prop\n",
    "    return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "637e19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def pronouns(example):\n",
    "    \"\"\"Label tweet as propaganda if has at least one pronoun.\"\"\"\n",
    "    pro_nouns = []\n",
    "    for word in example.docs.sentences[0].words:\n",
    "        if word.upos == \"PRON\":\n",
    "            pro_nouns.append(word.text)\n",
    "    if len(pro_nouns) >= 1:\n",
    "        return prop\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2f69cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the XLM-RoBERTa Zero-Shot model classes\n",
    "# candidate_labels = [\"transparent\", \"propaganda\"]\n",
    "candidate_labels = list(unlabeled_data.xlmroberta.unique())\n",
    "candidate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff795097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def xlmroberta_prop(example):\n",
    "    \"\"\"Label tweet as propaganda based on zero-shot model.\"\"\"\n",
    "    if pd.isna(example.xlmroberta_label):\n",
    "        return ab\n",
    "    if example.xlmroberta_label[\"scores\"][0] >= 0.90:\n",
    "        if example.xlmroberta_label[\"labels\"][0] == candidate_labels[-1]:\n",
    "            return prop\n",
    "        else:\n",
    "            return ab\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The included scores are fine-tuned.\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def xlmroberta_gen(example):\n",
    "    \"\"\"Label tweet as transparent based on zero-shot model.\"\"\"\n",
    "    if pd.isna(example.xlmroberta_label):\n",
    "        return ab\n",
    "    if example.xlmroberta_label[\"scores\"][0] >= 0.90:\n",
    "        if example.xlmroberta_label[\"labels\"][0] == candidate_labels[0]:\n",
    "            return gen\n",
    "        else:\n",
    "            return ab\n",
    "    else:\n",
    "        return ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "798f259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [\n",
    "    missing_bio,\n",
    "    missing_loc,\n",
    "    created_2018_2019,\n",
    "    created_2011_2012,\n",
    "    bio_keywords,\n",
    "    contain_url,\n",
    "    contain_mention,\n",
    "    labeling_sarcasm,\n",
    "    labeling_hate,\n",
    "    contain_ent,\n",
    "    ent_free,\n",
    "    contain_question,\n",
    "    loaded_language,\n",
    "    genuine_language,\n",
    "    loaded_proppy,\n",
    "    genuine_proppy,\n",
    "    loaded_hate,\n",
    "    loaded_sarcasm,\n",
    "    gen_hate,\n",
    "    gen_sarcasm,\n",
    "    flag_wave,\n",
    "    repetition,\n",
    "    distant_supervision_prop,\n",
    "    distant_supervision_gen,\n",
    "    slogans,\n",
    "    reductio,\n",
    "    exaggeration,\n",
    "    pronouns,\n",
    "    xlmroberta_prop,\n",
    "    xlmroberta_gen,\n",
    "]\n",
    "\n",
    "print(f\"We have {len(lfs)} LFs used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06873387",
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6373596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:49<00:00, 10.11it/s]\n"
     ]
    }
   ],
   "source": [
    "L_dev = applier.apply(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "764f0732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bio_keywords</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.052</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_url</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.026</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_irony</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.030</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_hate</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_free</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.158</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>0.955752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_language</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.096</td>\n",
       "      <td>32</td>\n",
       "      <td>54</td>\n",
       "      <td>0.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_language</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.570</td>\n",
       "      <td>398</td>\n",
       "      <td>16</td>\n",
       "      <td>0.961353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.560</td>\n",
       "      <td>36</td>\n",
       "      <td>282</td>\n",
       "      <td>0.113208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.106</td>\n",
       "      <td>170</td>\n",
       "      <td>12</td>\n",
       "      <td>0.934066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_hate</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_irony</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.044</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_prop</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.044</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_gen</th>\n",
       "      <td>12</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.110</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>0.951613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slogans</th>\n",
       "      <td>13</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reductio</th>\n",
       "      <td>14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exaggeration</th>\n",
       "      <td>15</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.118</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_prop</th>\n",
       "      <td>16</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_gen</th>\n",
       "      <td>17</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.066</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "bio_keywords               0      [0]     0.066     0.066      0.052       32   \n",
       "contain_url                1      [0]     0.044     0.044      0.026       21   \n",
       "labeling_irony             2      [1]     0.038     0.038      0.030        7   \n",
       "labeling_hate              3      [1]     0.020     0.020      0.020        2   \n",
       "ent_free                   4      [0]     0.226     0.226      0.158      108   \n",
       "loaded_language            5      [1]     0.172     0.172      0.096       32   \n",
       "genuine_language           6      [0]     0.828     0.828      0.570      398   \n",
       "loaded_proppy              7      [1]     0.636     0.636      0.560       36   \n",
       "genuine_proppy             8      [0]     0.364     0.364      0.106      170   \n",
       "loaded_hate                9      [1]     0.030     0.030      0.030        3   \n",
       "loaded_irony              10      [1]     0.052     0.052      0.044        8   \n",
       "distant_supervision_prop  11      [1]     0.054     0.054      0.044       11   \n",
       "distant_supervision_gen   12      [0]     0.124     0.124      0.110       59   \n",
       "slogans                   13      [1]     0.010     0.010      0.010        3   \n",
       "reductio                  14      [1]     0.014     0.014      0.012        4   \n",
       "exaggeration              15      [1]     0.130     0.130      0.118        8   \n",
       "xlmroberta_prop           16      [1]     0.028     0.028      0.028        4   \n",
       "xlmroberta_gen            17      [0]     0.108     0.108      0.066       48   \n",
       "\n",
       "                          Incorrect  Emp. Acc.  \n",
       "bio_keywords                      1   0.969697  \n",
       "contain_url                       1   0.954545  \n",
       "labeling_irony                   12   0.368421  \n",
       "labeling_hate                     8   0.200000  \n",
       "ent_free                          5   0.955752  \n",
       "loaded_language                  54   0.372093  \n",
       "genuine_language                 16   0.961353  \n",
       "loaded_proppy                   282   0.113208  \n",
       "genuine_proppy                   12   0.934066  \n",
       "loaded_hate                      12   0.200000  \n",
       "loaded_irony                     18   0.307692  \n",
       "distant_supervision_prop         16   0.407407  \n",
       "distant_supervision_gen           3   0.951613  \n",
       "slogans                           2   0.600000  \n",
       "reductio                          3   0.571429  \n",
       "exaggeration                     57   0.123077  \n",
       "xlmroberta_prop                  10   0.285714  \n",
       "xlmroberta_gen                    6   0.888889  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = LFAnalysis(L_dev, lfs).lf_summary(labeled_data.label.values)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d263b39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 196106/196106 [3:15:22<00:00, 16.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bio_keywords</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.325798</td>\n",
       "      <td>0.325798</td>\n",
       "      <td>0.298502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contain_url</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.460368</td>\n",
       "      <td>0.460368</td>\n",
       "      <td>0.397515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_irony</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.039678</td>\n",
       "      <td>0.039678</td>\n",
       "      <td>0.036149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labeling_hate</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.018306</td>\n",
       "      <td>0.018306</td>\n",
       "      <td>0.016904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ent_free</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.198796</td>\n",
       "      <td>0.198796</td>\n",
       "      <td>0.162463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_language</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.193334</td>\n",
       "      <td>0.193334</td>\n",
       "      <td>0.157155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_language</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>0.669301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_proppy</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.771537</td>\n",
       "      <td>0.771537</td>\n",
       "      <td>0.735357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genuine_proppy</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.228463</td>\n",
       "      <td>0.091099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_hate</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.021907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loaded_irony</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.051503</td>\n",
       "      <td>0.051503</td>\n",
       "      <td>0.047974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_prop</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.342855</td>\n",
       "      <td>0.342855</td>\n",
       "      <td>0.326053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distant_supervision_gen</th>\n",
       "      <td>12</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.145406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slogans</th>\n",
       "      <td>13</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.004885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reductio</th>\n",
       "      <td>14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>0.024375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exaggeration</th>\n",
       "      <td>15</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.208474</td>\n",
       "      <td>0.208474</td>\n",
       "      <td>0.199713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_prop</th>\n",
       "      <td>16</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.024410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmroberta_gen</th>\n",
       "      <td>17</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.117865</td>\n",
       "      <td>0.098850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts\n",
       "bio_keywords               0      [0]  0.325798  0.325798   0.298502\n",
       "contain_url                1      [0]  0.460368  0.460368   0.397515\n",
       "labeling_irony             2      [1]  0.039678  0.039678   0.036149\n",
       "labeling_hate              3      [1]  0.018306  0.018306   0.016904\n",
       "ent_free                   4      [0]  0.198796  0.198796   0.162463\n",
       "loaded_language            5      [1]  0.193334  0.193334   0.157155\n",
       "genuine_language           6      [0]  0.806666  0.806666   0.669301\n",
       "loaded_proppy              7      [1]  0.771537  0.771537   0.735357\n",
       "genuine_proppy             8      [0]  0.228463  0.228463   0.091099\n",
       "loaded_hate                9      [1]  0.023309  0.023309   0.021907\n",
       "loaded_irony              10      [1]  0.051503  0.051503   0.047974\n",
       "distant_supervision_prop  11      [1]  0.342855  0.342855   0.326053\n",
       "distant_supervision_gen   12      [0]  0.166400  0.166400   0.145406\n",
       "slogans                   13      [1]  0.005084  0.005084   0.004885\n",
       "reductio                  14      [1]  0.026348  0.026348   0.024375\n",
       "exaggeration              15      [1]  0.208474  0.208474   0.199713\n",
       "xlmroberta_prop           16      [1]  0.026419  0.026419   0.024410\n",
       "xlmroberta_gen            17      [0]  0.117865  0.117865   0.098850"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train = applier.apply(unlabeled_data)\n",
    "LFAnalysis(L_train, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e838a578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the LFs that maximize the performance of the label model\n",
    "inds = results[results[\"Emp. Acc.\"] >= 0.20].j.to_list()\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c32b32c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bio_keywords', 'contain_url', 'labeling_irony', 'labeling_hate', 'ent_free', 'loaded_language', 'genuine_language', 'genuine_proppy', 'loaded_hate', 'loaded_irony', 'distant_supervision_prop', 'distant_supervision_gen', 'slogans', 'reductio', 'xlmroberta_prop', 'xlmroberta_gen']\n"
     ]
    }
   ],
   "source": [
    "# displaying the names of the LFs chosen\n",
    "results.iloc[inds, :].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f96367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_ = L_train[:, inds].copy()\n",
    "L_dev_ = L_dev[:, inds].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating the class balance in the unlabeled data from the labeled.\n",
    "\n",
    "# w = labeled_data.label.value_counts(normalize=True).to_list()\n",
    "# w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c1a5fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c2f0e09bfe4689953566bf63ccbb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    }
   ],
   "source": [
    "# tuning the L2 regularization parameter to maximize the performance of the label model\n",
    "# we maximize the precision as it is need to surpass 50% for the noise-aware loss\n",
    "\n",
    "best_score = 0\n",
    "best_model = None\n",
    "l2_values = np.arange(0.0, 0.1, 0.01)\n",
    "\n",
    "for l2 in tqdm(l2_values, total=len(l2_values)):\n",
    "    label_model = LabelModel(cardinality=2, verbose=False, device=\"cuda\")\n",
    "    label_model.fit(\n",
    "        L_train=L_train_,\n",
    "        n_epochs=2000,\n",
    "        l2=l2,\n",
    "        lr=0.01,\n",
    "        seed=42,\n",
    "        class_balance=None,\n",
    "        progress_bar=False,\n",
    "        lr_scheduler=\"linear\",\n",
    "        optimizer=\"adam\",\n",
    "        lr_scheduler_config={\"warmup_percentage\": 0.1, \"warmup_unit\": \"epochs\"},\n",
    "    )\n",
    "    score = label_model.score(L_dev_, labeled_data.label, metrics=[\"precision\"])\n",
    "    if score[\"precision\"] >= best_score:\n",
    "        best_score = score[\"precision\"]\n",
    "        best_model = label_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3688b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainConfig(n_epochs=2000, lr=0.01, l2=0.03, optimizer='adam', optimizer_config=OptimizerConfig(sgd_config=SGDOptimizerConfig(momentum=0.9), adam_config=AdamOptimizerConfig(amsgrad=False, betas=(0.9, 0.999)), adamax_config=AdamaxOptimizerConfig(betas=(0.9, 0.999), eps=1e-08)), lr_scheduler='linear', lr_scheduler_config=LRSchedulerConfig(warmup_steps=0, warmup_unit='epochs', warmup_percentage=0.1, min_lr=0.0, exponential_config=ExponentialLRSchedulerConfig(gamma=0.9), step_config=StepLRSchedulerConfig(gamma=0.9, step_size=5)), prec_init=0.7, seed=42, log_freq=10, mu_eps=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the configs that led to the best label model\n",
    "best_model.train_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042015bd",
   "metadata": {},
   "source": [
    "Reporting the performance of the label model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d3fff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.858,\n",
       " 'precision': 0.3707865168539326,\n",
       " 'recall': 0.6875,\n",
       " 'f1': 0.4817518248175182,\n",
       " 'f1_macro': 0.6997403388282262,\n",
       " 'f1_micro': 0.858}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(\n",
    "    L_dev_,\n",
    "    labeled_data.label,\n",
    "    tie_break_policy=\"abstain\",\n",
    "    metrics=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"f1_macro\", \"f1_micro\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "927812c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labeled_data.label\n",
    "y_pred = best_model.predict(L_dev_)\n",
    "y_true = y_true[y_pred != -1]\n",
    "y_pred = y_pred[y_pred != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "64acbca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       452\n",
      "           1       0.37      0.69      0.48        48\n",
      "\n",
      "    accuracy                           0.86       500\n",
      "   macro avg       0.67      0.78      0.70       500\n",
      "weighted avg       0.91      0.86      0.88       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f60bf",
   "metadata": {},
   "source": [
    "Saving the weakly labeled dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "062a5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data[\"snorkel\"] = best_model.predict(L_dev_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cfb99ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the datasets\n",
    "weak_preds = best_model.predict(L_train_)\n",
    "unlabeled_data[\"label\"] = weak_preds\n",
    "unlabeled_data = unlabeled_data[weak_preds != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f3a2f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data[[\"tweetid\", \"text\", \"label\"]].to_json(weakly_labeled_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
